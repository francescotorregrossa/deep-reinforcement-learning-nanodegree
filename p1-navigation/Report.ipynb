{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "---\n",
    "\n",
    "The environment for this project is [Banana](https://github.com/udacity/deep-reinforcement-learning/tree/master/p1_navigation) from Unity, and it's provided in the `setup` folder. We'll implement the original [DQN algorithm](https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf) (but not directly from pixels) and two variations, [Double Q-Learning](https://arxiv.org/pdf/1509.06461.pdf) and [Dueling DQN](https://arxiv.org/pdf/1511.06581.pdf). Results will be compared in this notebook and the best solution will be implemented in `main.py`.\n",
    "\n",
    "## 1. Prepare dependencies and environment\n",
    "\n",
    "Take a look at README.md before executing this notebook and make sure that the kernel is set to **p1_navigation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install ./setup\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from numpy_ringbuffer import RingBuffer\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "\n",
    "from setup import unityagents\n",
    "from unityagents import UnityEnvironment\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unity environments contain **brains**, our interfaces for controlling agents. We'll be conrtolling the first (default) brain in the environment. It's also useful to keep information such as `state_size` and `action_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:unityagents:\n'Academy' started successfully!\nUnity Academy name: Academy\n        Number of Brains: 1\n        Number of External Brains : 1\n        Lesson number : 0\n        Reset Parameters :\n\t\t\nUnity brain name: BananaBrain\n        Number of Visual Observations (per agent): 0\n        Vector Observation space type: continuous\n        Vector Observation space size (per agent): 37\n        Number of stacked Vector Observation: 1\n        Vector Action space type: discrete\n        Vector Action space size (per agent): 4\n        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"setup/Banana.app\")\n",
    "\n",
    "# use the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "action_size = brain.vector_action_space_size\n",
    "state = env_info.vector_observations[0]\n",
    "state_size = len(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Experience replay\n",
    "\n",
    "In a classical Q-Learning setting, the agent learns immediately from experiences, and then discards them. In DQN, instead, experiences are stored as tuples and learning is delayed and performed in sampled batches. Sampling is fundamental since it removes **correlations in the sequence of observations** and it also allows to learn from a more comprehensive set of tuples, promoting exploration and avoiding **feedback loops**.\n",
    "\n",
    "We'll use the **uniform** variation of the replay buffer here, meaning that all stored tuples have the same chance of being selected for replay. The buffer has fixed `capacity` and will delete older tuples as newer ones arrive.\n",
    "\n",
    "Every tuple is stored as `(s, a, r, ns, d)` where:\n",
    "\n",
    "- `s` is the state at the beginning of the timestep\n",
    "- `a` is the action that was taken\n",
    "- `r` is the reward obtained in the next timestep\n",
    "- `ns` is the state at the next timestep (we'll refer to this as $s'$ as well)\n",
    "- `d` is a boolean value that determines if the episode ended\n",
    "\n",
    "When sampling a batch of `n` tuples, we'll obtain a single tuple `([s], [a], [r], [ns], [d])` where:\n",
    "- `[s]`, `[a]`, `[r]`, `[ns]`, `[d]` are **torch tensors** with `n` rows. Keep in mind that `[s]` and `[ns]` can have more than one column, depending on the `state_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniformReplayBuffer():\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.buff = RingBuffer(capacity=self.capacity, dtype=object)\n",
    "    \n",
    "    def sample(self, n, replace=True):\n",
    "        samples = np.random.choice(np.array(self.buff), n, replace)\n",
    "        \n",
    "        s = torch.FloatTensor([sample[0] for sample in samples]).to(device)\n",
    "        a = torch.LongTensor([sample[1] for sample in samples]).to(device)\n",
    "        r = torch.FloatTensor([sample[2] for sample in samples]).to(device)\n",
    "        ns = torch.FloatTensor([sample[3] for sample in samples]).to(device)\n",
    "        d = torch.FloatTensor([sample[4] for sample in samples]).to(device)\n",
    "        \n",
    "        return s, a, r, ns, d\n",
    "    \n",
    "    def add(self, observation):\n",
    "        s, a, r, ns, d = observation\n",
    "        self.buff.append((s, a, r, ns, d))\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.buff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Q Network\n",
    "\n",
    "We have two choices for this network's architecture:\n",
    "\n",
    "- `DQN`, the original Deep Q-Network\n",
    "- `DuelingDQN`, the Dueling Deep Q-Network\n",
    "\n",
    "Both models receive the current state $s$ as input and provide a vector for all estimated $Q(s, a)$ values at once.\n",
    "\n",
    "### 3.1 DQN\n",
    "\n",
    "The `DQN` class is straightforward and uses less parameters, since it only uses one stream of fully connected layers:\n",
    "\n",
    "- `state_size` $\\to 64$ followed by `relu` activations\n",
    "- $64 \\to 128$ and `relu`\n",
    "- $128 \\to 64$ and `relu`\n",
    "- $64 \\to Q(s, a)$, that is $64 \\to$ `action_size` and no activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    \n",
    "    def __init__(self, state_size, action_size, hidden_layers=[64, 128, 64]):\n",
    "        super(DQN, self).__init__()\n",
    "        \n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(state_size, hidden_layers[0])])\n",
    "        \n",
    "        A = hidden_layers[:-1]  # -> [64, 128] (using the predefined values)\n",
    "        B = hidden_layers[1:]   # -> [128, 64]\n",
    "        in_out = zip(A, B)      # -> [(64, 128), (128, 64)]\n",
    "        self.hidden_layers.extend([nn.Linear(a, b) for a, b in in_out])\n",
    "        \n",
    "        self.output_layer = nn.Linear(hidden_layers[-1], action_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        for layer in self.hidden_layers:\n",
    "            state = layer(state)\n",
    "            state = F.relu(state)\n",
    "        state = self.output_layer(state)\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 DuelingDQN\n",
    "\n",
    "On the other hand, `DuelingDQN` has two streams of independent layers: the **value** of a state $V(s)$ (scalar) and the **advantage** of taking an action $A(s, a)$ (same shape as the output), related by $A(s, a) = Q(s, a) - V(s)$. The idea is that, in many scenarios, the value of a state won't depend that much on the action the agent takes, so decoupling these values can help make better estimates.\n",
    "\n",
    "Thus, the class `DuelingDQN` uses two identical streams of independent fully connected layers:\n",
    "\n",
    "- `state_size` $\\to 32$ and `relu`\n",
    "- $32 \\to 128$ and `relu`\n",
    "- $128 \\to 32$ and `relu`\n",
    "\n",
    "The streams end in:\n",
    "\n",
    "- $32 \\to A(s, a)$, that is $32 \\to$ `action_size` and no activation\n",
    "- $32 \\to V(s)$, that is $32 \\to 1$ and no activation\n",
    "\n",
    "To merge them, however, we can't simply add $V$ and $A$ as $Q(s, a) = V(s) + A(s, a)$, because $A$ and $V$ **won't be identifiable**. We can, instead, write\n",
    "\n",
    "$$Q(s, a) = V(s) + A(s, a) - \\max_{a'} A(S, a')$$\n",
    "\n",
    "so that when the best action $a^*$ is selected, we get that $Q(s, a^*) = V(s)$, something that is not guaranteed otherwise. To further improve this, we can substitute the $\\max$ operator for a mean of the available actions. This is the final equation used in the `DuelingDQN` class, where $|\\mathbb{A}(s)| =$ `action_size`.\n",
    "\n",
    "$$Q(s, a) = V(s) + A(s, a) - \\frac{1}{|\\mathbb{A}(s)|} \\sum_{a' \\in \\mathbb{A}(s)} A(s, a')$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DuelingDQN(nn.Module):\n",
    "\n",
    "    def __init__(self, state_size, action_size, hidden_layers=[32, 128, 32]):\n",
    "        super(DuelingDQN, self).__init__()\n",
    "        \n",
    "        self.value_hidden_layers = nn.ModuleList([nn.Linear(state_size, hidden_layers[0])])\n",
    "        self.advantage_hidden_layers = nn.ModuleList([nn.Linear(state_size, hidden_layers[0])])\n",
    "        \n",
    "        A = hidden_layers[:-1]  # -> [32, 128] (using the predefined values)\n",
    "        B = hidden_layers[1:]   # -> [128, 32]\n",
    "        # zip(A, B)             # -> [(32, 128), (128, 32)]\n",
    "        self.value_hidden_layers.extend([nn.Linear(a, b) for a, b in zip(A, B)])\n",
    "        self.advantage_hidden_layers.extend([nn.Linear(a, b) for a, b in zip(A, B)])\n",
    "        \n",
    "        self.value_output_layer = nn.Linear(hidden_layers[-1], 1)\n",
    "        self.advantage_output_layer = nn.Linear(hidden_layers[-1], action_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        V = x\n",
    "        A = x.clone()\n",
    "        for value_layer, advantage_layer in zip(self.value_hidden_layers, self.advantage_hidden_layers):\n",
    "            V, A = value_layer(V), advantage_layer(A)\n",
    "            V, A = F.relu(V), F.relu(A)\n",
    "        V, A = self.value_output_layer(V), self.advantage_output_layer(A)\n",
    "        return V + A - torch.mean(A, dim=1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Temporal-Difference error estimation\n",
    "\n",
    "When we're calculating the **temporal-difference** error $\\delta_t$ we have to rely on an estimate of future returns. Two proposed variants for this are fixed Q-targets and Double DQN.\n",
    "\n",
    "The functions `dt_dqn`, `dt_double_dqn` implement the two variants. Both take an extra boolean parameter `d` that signals when the episode is over, since in that case, there is no future return and the TD error is simply $\\delta_t = r - Q(s, a)$.\n",
    "\n",
    "Note that these functions expect `s`, `a`, `r`, `ns` and `d` as **torch tensors**, where the number of rows corresponds to the batch size. The return value is also a vector with the same number of rows, one for each tuple.\n",
    "\n",
    "#### 4.1 Fixed Q-targets\n",
    "\n",
    "Due to the nature of neural networks (and function approximators in general), if we were to use the same Q network for both $Q(s, a)$ and $Q(s', a')$, a gradient descent step that is meant to improve the former would modify the latter as well, making learning unstable. Because of this – and also because we want to preserve mathematical correctness in the derivative – we use two different networks, $Q_{local}$ and $Q_{target}$.\n",
    "\n",
    "This method is called fixed Q-targets, and it essentially **duplicates the network**, using $Q_{local}$ to determine the policy and $Q_{target}$ to estimate future returns. The latter is updated less frequently by copying (or interpolating towards) the parameters of the former, so that they're different enough to avoid instability. The equation for $\\delta_t$ is\n",
    "\n",
    "$$\\delta_t(s, a, r, s') = r + \\gamma \\max_{a'} Q_{target}(s', a') - Q_{local}(s, a)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt_dqn(s, a, r, ns, d, q_local, q_target, gamma):\n",
    "    with torch.no_grad():   # no need for gradients when we're evaluating the TD target\n",
    "        QT = q_target(ns)   # evaluate the next state using the target network (out: [n * action_size])\n",
    "        QT = QT.max(1)      # take the max along the column (actions) (out: two tensors [n])\n",
    "        QT = QT[0]          # - [0] has the max values for each element in the batch, \n",
    "                            # - [1] has the indexes of the max values\n",
    "\n",
    "    a = a.unsqueeze(1)      # reshape [n] -> [n * 1]\n",
    "    QL = q_local(s)         # evaluate the current state using the local network (out: [n * action_size])\n",
    "    QL = QL.gather(1, a)    # for each row, take the column in QL indicated by a (out: [n * 1])\n",
    "    QL = QL.squeeze(1)      # reshape [n * 1] -> [n]\n",
    "\n",
    "    return r + gamma * QT * (1 - torch.tensor(d.to(device))) - QL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Double DQN\n",
    "\n",
    "This is largely based on fixed Q-targets, since it also uses $Q_{local}$ and $Q_{target}$. We can rewrite $\\max Q$ using $\\arg \\max$ to break down the task of **choosing** and **evaluating** an action in two different steps.\n",
    "\n",
    "$$\\max_{a'} Q_{target}(s', a') = Q_{target}(s', \\arg \\max_{a'} Q_{target}(s', a'))$$\n",
    "\n",
    "This can lead to the **overestimation** of targets. Simply put, when taking the $\\max$ among noisy numbers (which is especially true in the beginning) we're likely to pick the action where the approximator adds more positive noise. Separating the task of picking and evaluating the action to two different approximators may decrease this issue, since both networks now have to \"agree\" on the outcome of an action.\n",
    "\n",
    "The original estimate can be improved using the one provided in the Double DQN paper. The proposed solution is to use $Q_{local}$ for the choice and $Q_{target}$ for the evaluation as follows\n",
    "\n",
    "$$\n",
    "Q_{target}(s', \\arg \\max_{a'} Q_{local}(s', a'))\\\\\n",
    "\\implies \\delta_t(s, a, r, s') = r + \\gamma Q_{target}(s', \\arg \\max_{a'} Q_{local}(s', a')) - Q_{local}(s, a)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt_double_dqn(s, a, r, ns, d, q_local, q_target, gamma):\n",
    "    with torch.no_grad():         # no need for gradients when we're evaluating the TD target\n",
    "        QLns = q_local(ns)        # evaluate the next state using the local network (out: [n * action_size])\n",
    "        QLns = QLns.max(1)        # take the max along the column (actions) (out: two tensors [n])\n",
    "        QLns = QLns[1]            # [1] has the indexes of the max values\n",
    "        QLns = QLns.unsqueeze(1)  # reshape [n] -> [n * 1]\n",
    "\n",
    "        QT = q_target(ns)         # evaluate the next state using the target network (out: [n * action_size])\n",
    "        QT = QT.gather(1, QLns)   # for each row, take the value estimated by the target network for\n",
    "                                  # the best action estimated by the local network (out: [n * 1])\n",
    "        QT = QT.squeeze(1)        # reshape [n * 1] -> [n]\n",
    "\n",
    "    a = a.unsqueeze(1)            # reshape [n] -> [n * 1]\n",
    "    QL = q_local(s)               # evaluate the current state using the local network (out: [n * action_size])\n",
    "    QL = QL.gather(1, a)          # for each row, take the column in QL indicated by a (out: [n * 1])\n",
    "    QL = QL.squeeze(1)            # reshape [n * 1] -> [n]\n",
    "\n",
    "    return r + gamma * QT * (1 - torch.tensor(d.to(device))) - QL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Agent\n",
    "\n",
    "Let's put the pieces together. During initialization, we can configure the agent's:\n",
    "\n",
    "- `QNetwork`, which is either the class `DQN` or `DuelingDQN` (_not an instance_)\n",
    "- `replay_buffer`, which is an instance of `UniformReplayBuffer`\n",
    "- `Delta`, which is either the function `dt_dqn` or `dt_double_dqn`\n",
    "\n",
    "Other parameters are obviously `state_size` and `action_size` as well as some hyperparameters:\n",
    "\n",
    "- `alpha` $\\in [0, 1]$, the learning rate to apply to gradient steps to `q_local`\n",
    "- `eps`, `eps_decay` and `min_eps` $\\in [0, 1]$, for the $\\epsilon$-greedy policy, if `learning = False` only the greedy policy will be used\n",
    "- `gamma` $\\in [0, 1]$, the weight of the estimates for future returns calculated by `q_target` in the function `Delta`\n",
    "- `tau` $\\in [0, 1]$, to perform soft updates of `q_target` (if set to $1$ directly copies `q_local` into `q_target`)\n",
    "- `update_every` the number of steps to wait before updating `q_local` and `q_target`\n",
    "- `batch_size` the number of samples from the `replay_buffer` used to perform one update of `q_local`\n",
    "\n",
    "The agent has three functions, but only the first two should be called from the outside: \n",
    "- `act`, based on a state tensor `s` and on `eps`, choose an action. If the agent has `learning = False` the choice will be greedy.\n",
    "- `store`, receive a tuple to put in the `replay_buffer`. This counts as a step towards the updates of `q_local` and `q_target`, and in fact calls `learn()` automatically when needed.\n",
    "- `learn`, samples a batch of tuples from the `replay_buffer`, calculates their $\\delta_t$ and finally performs gradient descent on `q_local` and a soft update of `q_target` towards `q_local`. Note that it can already perform actions related to a tuple's priority and importance sampling weight.\n",
    "\n",
    "Additionally, an agent can be `reset()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetworkAgent():\n",
    "    \n",
    "    def __init__(self, QNetwork, state_size, action_size, \n",
    "                 replay_buffer, Delta, \n",
    "                 eps=1, eps_decay=0.9995, min_eps=0.0001, gamma=0.99, \n",
    "                 alpha=0.001, tau=0.01,\n",
    "                 update_every=15, batch_size=64, learning=True):\n",
    "        self.state_size, self.action_size = state_size, action_size\n",
    "        self.original_eps = eps\n",
    "        self.QNetwork = QNetwork\n",
    "        self.replay_buffer = replay_buffer\n",
    "        self.Delta = Delta\n",
    "        self.learning = learning\n",
    "        self.eps, self.eps_decay, self.min_eps = eps, eps_decay, min_eps\n",
    "        self.gamma, self.alpha, self.tau = gamma, alpha, tau\n",
    "        self.update_every, self.batch_size = update_every, batch_size\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.replay_buffer.reset()\n",
    "        self.eps = self.original_eps\n",
    "        self.q_local = self.QNetwork(self.state_size, self.action_size).to(device)\n",
    "        self.q_target = self.QNetwork(self.state_size, self.action_size).to(device)\n",
    "        self.optimizer = optim.Adam(self.q_local.parameters(), lr=self.alpha)\n",
    "        self.update_i = 0\n",
    "\n",
    "    def act(self, s):\n",
    "        if not self.learning or np.random.uniform() > self.eps:\n",
    "            with torch.no_grad():\n",
    "                s = torch.FloatTensor(s).unsqueeze(0).to(device)  # out: [1 * action_size]\n",
    "                return int(self.q_local(s).max(1)[1])\n",
    "        else:\n",
    "            return np.random.randint(self.action_size)\n",
    "    \n",
    "    def store(self, s, a, r, ns, d):\n",
    "        self.replay_buffer.add((s, a, r, ns, d))\n",
    "        if self.update_i == 0 and self.replay_buffer.size() >= self.batch_size:\n",
    "            self.learn()\n",
    "            self.eps = max(self.eps * self.eps_decay, self.min_eps)\n",
    "        self.update_i = (self.update_i + 1) % self.update_every\n",
    "    \n",
    "    def learn(self):\n",
    "        s, a, r, ns, d = self.replay_buffer.sample(self.batch_size)\n",
    "        td_delta = self.Delta(s, a, r, ns, d, self.q_local, self.q_target, self.gamma)\n",
    "                \n",
    "        self.optimizer.zero_grad()\n",
    "        loss = torch.mean(td_delta ** 2)  # mean squared error\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():  # soft updates of q_target don't need autograd, since they're copied (or interpolated) from q_local\n",
    "            for local, target in zip(self.q_local.parameters(), self.q_target.parameters()):\n",
    "                target.copy_(target + self.tau * (local - target))"
   ]
  },
  {
   "source": [
    "Creating an agent is straightforward now. We can make four agents, one for each combination of things that we've defined earlier. Note that these agents share the same default hyperparameters that were chosen after some tests:\n",
    "\n",
    "- `eps=1`, `eps_decay=0.9995`, `min_eps=0.0001`,\n",
    "- `gamma=0.99`\n",
    "- `alpha=0.001`\n",
    "- `tau=0.01`\n",
    "- `update_every=15`\n",
    "- `batch_size=64`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = [('DQN', QNetworkAgent(DQN, state_size, action_size, UniformReplayBuffer(100_000), dt_dqn)),\n",
    "          ('Double DQN', QNetworkAgent(DQN, state_size, action_size, UniformReplayBuffer(100_000), dt_double_dqn)),\n",
    "          ('Dueling DQN', QNetworkAgent(DuelingDQN, state_size, action_size, UniformReplayBuffer(100_000), dt_dqn)),\n",
    "          ('Dueling Double DQN', QNetworkAgent(DuelingDQN, state_size, action_size, UniformReplayBuffer(100_000), dt_double_dqn))]"
   ]
  },
  {
   "source": [
    "## 6. Training an agent\n",
    "\n",
    "What we define now is a function that connects our `agent` and `env`. Recall that we'll be using the default `brain_name` to interact with the environment. The agent is allowed to store observations and, consequently, learn every now and then (`update_every=15` steps)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_episode(agent, env):\n",
    "    env_info = env.reset(train_mode=True)[brain_name]\n",
    "    state = env_info.vector_observations[0]\n",
    "    score = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = agent.act(state)\n",
    "\n",
    "        env_info = env.step(action)[brain_name]\n",
    "        next_state = env_info.vector_observations[0]\n",
    "        reward = env_info.rewards[0]\n",
    "        done = env_info.local_done[0]\n",
    "\n",
    "        agent.store(state, action, reward, next_state, done)\n",
    "        score += reward\n",
    "        state = next_state\n",
    "    return score"
   ]
  },
  {
   "source": [
    "We can call the function above repeatedly while **monitoring** what happens, so that we'll be able to compare different approaches. The most important indicator is going to be the average score over 100 consecutive episodes: the environment is considered **solved when the agent scores +13 or more** under this metric. We'll be training each agent 3 times from scratch, for 1000 episodes, and we'll average the results. This way, the learning curves will depend less on the randomness of the environment, reflecting more accurately the differences in the approaches."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(agent, env, episode_function, episodes=1000, repeat=3, consecutive_episodes=100, show_output=True, save_as=None):\n",
    "\n",
    "    results = [None] * repeat\n",
    "    for r in range(repeat):\n",
    "        \n",
    "        agent.reset()\n",
    "        partial_results = [None] * episodes\n",
    "        for i in range(episodes):\n",
    "            score = episode_function(agent, env)\n",
    "            partial_results[i] = score\n",
    "            \n",
    "            if show_output:\n",
    "                print(\"\\r[{}] Episode: {}, Score: {}\".format(r+1, i+1, score), end=\"\")\n",
    "                sys.stdout.flush()\n",
    "        \n",
    "        if show_output:\n",
    "            print()\n",
    "\n",
    "        results[r] = partial_results\n",
    "    \n",
    "        if save_as is not None:\n",
    "            torch.save(agent.q_local.state_dict(), '{}/{}.pth'.format(save_as, r+1))\n",
    "\n",
    "    # use convolutions to calculate the mean and standard deviation summarizing the training step\n",
    "    results = np.array(results)\n",
    "    mean = signal.convolve2d(results, np.ones([repeat, consecutive_episodes]) / (repeat * consecutive_episodes), mode='valid')    \n",
    "    v = signal.convolve2d(results, np.ones([1, consecutive_episodes]) / consecutive_episodes, mode='valid')\n",
    "    std_dev = signal.convolve2d(v ** 2 - mean ** 2, np.ones([repeat, 1]) / repeat, mode='valid') ** (1/2)\n",
    "    return mean.flatten(), std_dev.flatten(), results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Agent: DQN\n",
      "[1] Episode: 27, Score: 0.0"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-86d43850e62d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Agent: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_report\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecute_episode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_as\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'models/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtraining_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_report\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-982725cb00af>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(agent, env, episode_function, episodes, repeat, consecutive_episodes, show_output, save_as)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mpartial_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mepisodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepisode_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mpartial_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-603969892e44>\u001b[0m in \u001b[0;36mexecute_episode\u001b[0;34m(agent, env)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0menv_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-355b9d56ba7f>\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# out: [1 * action_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_results = []\n",
    "for ag in agents:\n",
    "    name, agent = ag\n",
    "    print('Agent: {}'.format(name))\n",
    "    mean, std_dev, full_report = train(agent, env, episode_function=execute_episode, save_as='models/{}'.format(name.replace(\" \", \"_\")))\n",
    "    training_results.append((mean, std_dev, full_report))"
   ]
  },
  {
   "source": [
    "## 7. Comparing the results\n",
    "\n",
    "We can use `matplotlib` to plot the mean of the score and its standard deviation. Clearly all algorithms proposed manage to score an average of 13 points or more on 100 consecutive runs, thus solving the environment, and they do so in less than 500 episodes. Nonetheless, `Double DQN` and `Dueling DQN` allow the agent to perform even better and to solve the environment even earlier. In particular, `dt_double_dqn` seems to make learning **more stable** while `DuelingDQN` seems to approximate **more optimal** policies."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DQN: Solved after 375 episodes\nDouble DQN: Solved after 413 episodes\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"277.314375pt\" version=\"1.1\" viewBox=\"0 0 368.925 277.314375\" width=\"368.925pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2020-11-29T13:38:29.847967</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M -0 277.314375 \nL 368.925 277.314375 \nL 368.925 0 \nL -0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 239.758125 \nL 361.725 239.758125 \nL 361.725 22.318125 \nL 26.925 22.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"PolyCollection_1\">\n    <path clip-path=\"url(#p8207875bcf)\" d=\"M 42.143182 230.818925 \nL 42.143182 213.906925 \nL 42.904091 213.544525 \nL 43.665 212.578125 \nL 44.425909 211.490925 \nL 45.186818 210.645325 \nL 45.947727 209.678925 \nL 46.708636 209.074925 \nL 47.469545 208.954125 \nL 48.230455 207.504525 \nL 48.991364 206.538125 \nL 49.752273 206.054925 \nL 50.513182 205.934125 \nL 51.274091 205.450925 \nL 52.035 204.967725 \nL 52.795909 204.001325 \nL 53.556818 203.518125 \nL 54.317727 202.551725 \nL 55.078636 201.343725 \nL 55.839545 199.652525 \nL 56.600455 199.169325 \nL 57.361364 198.202925 \nL 58.122273 197.719725 \nL 58.883182 196.632525 \nL 59.644091 196.270125 \nL 60.405 195.303725 \nL 61.165909 193.974925 \nL 61.926818 193.733325 \nL 62.687727 193.491725 \nL 63.448636 193.370925 \nL 64.209545 192.404525 \nL 64.970455 192.042125 \nL 65.731364 190.713325 \nL 66.492273 189.626125 \nL 67.253182 189.022125 \nL 68.014091 188.176525 \nL 68.775 188.297325 \nL 69.535909 187.089325 \nL 70.296818 186.243725 \nL 71.057727 185.881325 \nL 71.818636 185.639725 \nL 72.579545 184.431725 \nL 73.340455 183.948525 \nL 74.101364 183.344525 \nL 74.862273 182.136525 \nL 75.623182 181.774125 \nL 76.384091 180.566125 \nL 77.145 179.962125 \nL 77.905909 178.995725 \nL 78.666818 177.546125 \nL 79.427727 175.854925 \nL 80.188636 175.734125 \nL 80.949545 174.888525 \nL 81.710455 173.197325 \nL 82.471364 172.230925 \nL 83.232273 172.230925 \nL 83.993182 170.781325 \nL 84.754091 170.660525 \nL 85.515 169.090125 \nL 86.275909 168.606925 \nL 87.036818 168.244525 \nL 87.797727 166.915725 \nL 88.558636 165.707725 \nL 89.319545 164.862125 \nL 90.080455 163.533325 \nL 90.841364 163.412525 \nL 91.602273 162.446125 \nL 92.363182 161.358925 \nL 93.124091 161.117325 \nL 93.885 160.150925 \nL 94.645909 160.513325 \nL 95.406818 159.305325 \nL 96.167727 158.338925 \nL 96.928636 157.734925 \nL 97.689545 157.010125 \nL 98.450455 156.406125 \nL 99.211364 155.681325 \nL 99.972273 154.594125 \nL 100.733182 153.869325 \nL 101.494091 152.902925 \nL 102.255 153.144525 \nL 103.015909 151.694925 \nL 103.776818 150.124525 \nL 104.537727 149.641325 \nL 105.298636 149.520525 \nL 106.059545 148.312525 \nL 106.820455 147.225325 \nL 107.581364 146.379725 \nL 108.342273 146.379725 \nL 109.103182 144.809325 \nL 109.864091 145.050925 \nL 110.625 144.326125 \nL 111.385909 143.118125 \nL 112.146818 143.842925 \nL 112.907727 143.842925 \nL 113.668636 144.205325 \nL 114.429545 143.118125 \nL 115.190455 141.426925 \nL 115.951364 140.702125 \nL 116.712273 139.494125 \nL 117.473182 137.802925 \nL 118.234091 137.561325 \nL 118.995 137.078125 \nL 119.755909 136.594925 \nL 120.516818 136.353325 \nL 121.277727 135.749325 \nL 122.038636 135.266125 \nL 122.799545 134.541325 \nL 123.560455 133.333325 \nL 124.321364 133.091725 \nL 125.082273 132.729325 \nL 125.843182 132.970925 \nL 126.604091 131.883725 \nL 127.365 130.675725 \nL 128.125909 129.346925 \nL 128.886818 128.380525 \nL 129.647727 128.018125 \nL 130.408636 128.622125 \nL 131.169545 128.742925 \nL 131.930455 128.259725 \nL 132.691364 127.534925 \nL 133.452273 127.172525 \nL 134.213182 126.085325 \nL 134.974091 126.810125 \nL 135.735 125.722925 \nL 136.495909 125.118925 \nL 137.256818 124.635725 \nL 138.017727 124.273325 \nL 138.778636 122.340525 \nL 139.539545 122.219725 \nL 140.300455 121.615725 \nL 141.061364 121.132525 \nL 141.822273 121.132525 \nL 142.583182 121.494925 \nL 143.344091 120.407725 \nL 144.105 119.803725 \nL 144.865909 118.474925 \nL 145.626818 118.474925 \nL 146.387727 117.750125 \nL 147.148636 117.750125 \nL 147.909545 117.266925 \nL 148.670455 117.025325 \nL 149.431364 115.454925 \nL 150.192273 115.575725 \nL 150.953182 115.696525 \nL 151.714091 114.609325 \nL 152.475 115.817325 \nL 153.235909 114.126125 \nL 153.996818 114.488525 \nL 154.757727 114.971725 \nL 155.518636 114.850925 \nL 156.279545 114.246925 \nL 157.040455 113.642925 \nL 157.801364 113.522125 \nL 158.562273 113.280525 \nL 159.323182 113.763725 \nL 160.084091 113.401325 \nL 160.845 111.830925 \nL 161.605909 111.830925 \nL 162.366818 110.864525 \nL 163.127727 110.622925 \nL 163.888636 110.139725 \nL 164.649545 109.535725 \nL 165.410455 108.931725 \nL 166.171364 108.690125 \nL 166.932273 107.965325 \nL 167.693182 108.206925 \nL 168.454091 108.327725 \nL 169.215 107.361325 \nL 169.975909 106.878125 \nL 170.736818 105.307725 \nL 171.497727 105.911725 \nL 172.258636 106.394925 \nL 173.019545 106.515725 \nL 173.780455 107.240525 \nL 174.541364 106.757325 \nL 175.302273 106.878125 \nL 176.063182 106.394925 \nL 176.824091 106.636525 \nL 177.585 106.998925 \nL 178.345909 105.307725 \nL 179.106818 106.274125 \nL 179.867727 106.878125 \nL 180.628636 106.636525 \nL 181.389545 106.998925 \nL 182.150455 106.757325 \nL 182.911364 106.636525 \nL 183.672273 105.186925 \nL 184.433182 104.220525 \nL 185.194091 105.307725 \nL 185.955 104.220525 \nL 186.715909 103.254125 \nL 187.476818 102.891725 \nL 188.237727 101.200525 \nL 188.998636 100.354925 \nL 189.759545 98.905325 \nL 190.520455 99.146925 \nL 191.281364 99.026125 \nL 192.042273 97.334925 \nL 192.803182 97.093325 \nL 193.564091 97.455725 \nL 194.325 96.730925 \nL 195.085909 95.764525 \nL 195.846818 95.160525 \nL 196.607727 94.798125 \nL 197.368636 94.677325 \nL 198.129545 93.710925 \nL 198.890455 93.469325 \nL 199.651364 93.469325 \nL 200.412273 93.106925 \nL 201.173182 91.778125 \nL 201.934091 91.778125 \nL 202.695 91.778125 \nL 203.455909 91.536525 \nL 204.216818 92.744525 \nL 204.977727 92.865325 \nL 205.738636 92.502925 \nL 206.499545 91.294925 \nL 207.260455 91.294925 \nL 208.021364 91.053325 \nL 208.782273 90.570125 \nL 209.543182 89.482925 \nL 210.304091 89.482925 \nL 211.065 88.274925 \nL 211.825909 87.912525 \nL 212.586818 86.946125 \nL 213.347727 87.670925 \nL 214.108636 86.221325 \nL 214.869545 86.825325 \nL 215.630455 85.617325 \nL 216.391364 85.134125 \nL 217.152273 83.926125 \nL 217.913182 82.959725 \nL 218.674091 82.355725 \nL 219.435 82.234925 \nL 220.195909 81.510125 \nL 220.956818 81.872525 \nL 221.717727 82.597325 \nL 222.478636 82.355725 \nL 223.239545 80.906125 \nL 224.000455 80.906125 \nL 224.761364 80.906125 \nL 225.522273 81.872525 \nL 226.283182 81.389325 \nL 227.044091 81.389325 \nL 227.805 82.234925 \nL 228.565909 81.630925 \nL 229.326818 82.718125 \nL 230.087727 81.389325 \nL 230.848636 80.906125 \nL 231.609545 81.268525 \nL 232.370455 81.872525 \nL 233.131364 82.355725 \nL 233.892273 83.080525 \nL 234.653182 83.080525 \nL 235.414091 81.268525 \nL 236.175 81.510125 \nL 236.935909 81.993325 \nL 237.696818 81.026925 \nL 238.457727 81.389325 \nL 239.218636 80.543725 \nL 239.979545 80.422925 \nL 240.740455 82.114125 \nL 241.501364 82.597325 \nL 242.262273 83.322125 \nL 243.023182 83.926125 \nL 243.784091 83.080525 \nL 244.545 81.993325 \nL 245.305909 81.147725 \nL 246.066818 80.422925 \nL 246.827727 79.577325 \nL 247.588636 78.852525 \nL 248.349545 77.644525 \nL 249.110455 76.678125 \nL 249.871364 75.349325 \nL 250.632273 74.503725 \nL 251.393182 73.778925 \nL 252.154091 73.054125 \nL 252.915 72.570925 \nL 253.675909 72.329325 \nL 254.436818 72.933325 \nL 255.197727 72.208525 \nL 255.958636 71.966925 \nL 256.719545 71.483725 \nL 257.480455 71.483725 \nL 258.241364 71.121325 \nL 259.002273 70.154925 \nL 259.763182 70.638125 \nL 260.524091 71.483725 \nL 261.285 71.000525 \nL 262.045909 70.758925 \nL 262.806818 70.517325 \nL 263.567727 71.000525 \nL 264.328636 70.517325 \nL 265.089545 71.604525 \nL 265.850455 71.483725 \nL 266.611364 71.362925 \nL 267.372273 71.846125 \nL 268.133182 72.812525 \nL 268.894091 71.966925 \nL 269.655 71.604525 \nL 270.415909 71.483725 \nL 271.176818 71.121325 \nL 271.937727 72.570925 \nL 272.698636 73.174925 \nL 273.459545 72.933325 \nL 274.220455 73.899725 \nL 274.981364 73.899725 \nL 275.742273 73.295725 \nL 276.503182 73.537325 \nL 277.264091 74.986925 \nL 278.025 73.174925 \nL 278.785909 71.846125 \nL 279.546818 72.450125 \nL 280.307727 71.242125 \nL 281.068636 70.758925 \nL 281.829545 69.913325 \nL 282.590455 69.188525 \nL 283.351364 68.826125 \nL 284.112273 70.154925 \nL 284.873182 70.154925 \nL 285.634091 71.000525 \nL 286.395 71.725325 \nL 287.155909 71.362925 \nL 287.916818 71.121325 \nL 288.677727 71.604525 \nL 289.438636 70.758925 \nL 290.199545 72.208525 \nL 290.960455 73.537325 \nL 291.721364 72.691725 \nL 292.482273 73.174925 \nL 293.243182 72.691725 \nL 294.004091 72.933325 \nL 294.765 72.812525 \nL 295.525909 72.933325 \nL 296.286818 71.362925 \nL 297.047727 70.758925 \nL 297.808636 70.275725 \nL 298.569545 71.242125 \nL 299.330455 69.913325 \nL 300.091364 67.980525 \nL 300.852273 69.550925 \nL 301.613182 69.671725 \nL 302.374091 68.705325 \nL 303.135 68.463725 \nL 303.895909 67.014125 \nL 304.656818 67.980525 \nL 305.417727 67.980525 \nL 306.178636 68.222125 \nL 306.939545 67.980525 \nL 307.700455 68.222125 \nL 308.461364 67.134925 \nL 309.222273 66.168525 \nL 309.983182 65.322925 \nL 310.744091 65.443725 \nL 311.505 64.235725 \nL 312.265909 64.114925 \nL 313.026818 64.598125 \nL 313.787727 64.356525 \nL 314.548636 65.322925 \nL 315.309545 64.598125 \nL 316.070455 65.322925 \nL 316.831364 63.752525 \nL 317.592273 63.873325 \nL 318.353182 63.269325 \nL 319.114091 62.423725 \nL 319.875 62.544525 \nL 320.635909 63.752525 \nL 321.396818 63.631725 \nL 322.157727 60.853325 \nL 322.918636 61.457325 \nL 323.679545 62.182125 \nL 324.440455 62.182125 \nL 325.201364 61.819725 \nL 325.962273 61.457325 \nL 326.723182 61.698925 \nL 327.484091 60.974125 \nL 328.245 60.249325 \nL 329.005909 59.403725 \nL 329.766818 58.799725 \nL 330.527727 59.886925 \nL 331.288636 60.611725 \nL 332.049545 60.370125 \nL 332.810455 60.732525 \nL 333.571364 61.336525 \nL 334.332273 60.611725 \nL 335.093182 59.886925 \nL 335.854091 60.128525 \nL 336.615 60.732525 \nL 337.375909 60.732525 \nL 338.136818 60.007725 \nL 338.897727 59.282925 \nL 339.658636 58.799725 \nL 340.419545 58.678925 \nL 341.180455 58.316525 \nL 341.941364 57.470925 \nL 342.702273 56.383725 \nL 343.463182 55.658925 \nL 344.224091 55.779725 \nL 344.985 56.262925 \nL 345.745909 55.417325 \nL 346.506818 56.504525 \nL 346.506818 66.168525 \nL 346.506818 66.168525 \nL 345.745909 65.564525 \nL 344.985 64.477325 \nL 344.224091 64.356525 \nL 343.463182 64.598125 \nL 342.702273 64.598125 \nL 341.941364 65.202125 \nL 341.180455 64.718925 \nL 340.419545 66.530925 \nL 339.658636 65.685325 \nL 338.897727 64.356525 \nL 338.136818 62.061325 \nL 337.375909 62.544525 \nL 336.615 61.819725 \nL 335.854091 62.665325 \nL 335.093182 62.665325 \nL 334.332273 61.698925 \nL 333.571364 61.457325 \nL 332.810455 63.269325 \nL 332.049545 63.148525 \nL 331.288636 63.631725 \nL 330.527727 64.235725 \nL 329.766818 64.839725 \nL 329.005909 65.926925 \nL 328.245 65.564525 \nL 327.484091 65.564525 \nL 326.723182 65.564525 \nL 325.962273 65.322925 \nL 325.201364 65.322925 \nL 324.440455 66.047725 \nL 323.679545 65.685325 \nL 322.918636 65.685325 \nL 322.157727 64.839725 \nL 321.396818 64.235725 \nL 320.635909 63.994125 \nL 319.875 63.873325 \nL 319.114091 63.873325 \nL 318.353182 64.356525 \nL 317.592273 65.443725 \nL 316.831364 66.047725 \nL 316.070455 67.859725 \nL 315.309545 67.859725 \nL 314.548636 67.980525 \nL 313.787727 68.222125 \nL 313.026818 66.289325 \nL 312.265909 66.772525 \nL 311.505 66.410125 \nL 310.744091 66.289325 \nL 309.983182 67.618125 \nL 309.222273 68.222125 \nL 308.461364 68.826125 \nL 307.700455 69.792525 \nL 306.939545 70.396525 \nL 306.178636 69.309325 \nL 305.417727 68.705325 \nL 304.656818 69.550925 \nL 303.895909 70.275725 \nL 303.135 70.879725 \nL 302.374091 70.758925 \nL 301.613182 72.087725 \nL 300.852273 72.570925 \nL 300.091364 72.329325 \nL 299.330455 73.174925 \nL 298.569545 73.658125 \nL 297.808636 73.778925 \nL 297.047727 74.866125 \nL 296.286818 75.349325 \nL 295.525909 74.141325 \nL 294.765 74.020525 \nL 294.004091 73.658125 \nL 293.243182 72.933325 \nL 292.482273 73.658125 \nL 291.721364 74.382925 \nL 290.960455 75.349325 \nL 290.199545 76.315725 \nL 289.438636 76.436525 \nL 288.677727 77.161325 \nL 287.916818 77.523725 \nL 287.155909 76.436525 \nL 286.395 76.919725 \nL 285.634091 77.523725 \nL 284.873182 78.731725 \nL 284.112273 79.214925 \nL 283.351364 78.731725 \nL 282.590455 78.369325 \nL 281.829545 78.610925 \nL 281.068636 78.490125 \nL 280.307727 78.490125 \nL 279.546818 80.181325 \nL 278.785909 80.422925 \nL 278.025 80.422925 \nL 277.264091 81.389325 \nL 276.503182 82.355725 \nL 275.742273 82.234925 \nL 274.981364 82.355725 \nL 274.220455 81.510125 \nL 273.459545 81.630925 \nL 272.698636 81.993325 \nL 271.937727 82.114125 \nL 271.176818 81.872525 \nL 270.415909 83.201325 \nL 269.655 84.046925 \nL 268.894091 85.496525 \nL 268.133182 85.858925 \nL 267.372273 86.100525 \nL 266.611364 86.704525 \nL 265.850455 86.221325 \nL 265.089545 85.013325 \nL 264.328636 85.254925 \nL 263.567727 85.496525 \nL 262.806818 86.825325 \nL 262.045909 87.429325 \nL 261.285 87.308525 \nL 260.524091 87.670925 \nL 259.763182 88.033325 \nL 259.002273 88.758125 \nL 258.241364 90.328525 \nL 257.480455 89.724525 \nL 256.719545 89.724525 \nL 255.958636 89.724525 \nL 255.197727 89.845325 \nL 254.436818 90.570125 \nL 253.675909 91.174125 \nL 252.915 91.898925 \nL 252.154091 91.898925 \nL 251.393182 91.294925 \nL 250.632273 91.898925 \nL 249.871364 92.382125 \nL 249.110455 93.106925 \nL 248.349545 93.469325 \nL 247.588636 93.590125 \nL 246.827727 93.227725 \nL 246.066818 94.194125 \nL 245.305909 92.865325 \nL 244.545 93.348525 \nL 243.784091 93.831725 \nL 243.023182 94.314925 \nL 242.262273 92.744525 \nL 241.501364 93.348525 \nL 240.740455 94.314925 \nL 239.979545 92.865325 \nL 239.218636 93.952525 \nL 238.457727 94.435725 \nL 237.696818 95.160525 \nL 236.935909 95.764525 \nL 236.175 97.334925 \nL 235.414091 98.301325 \nL 234.653182 98.663725 \nL 233.892273 99.630125 \nL 233.131364 99.509325 \nL 232.370455 99.871725 \nL 231.609545 100.113325 \nL 230.848636 101.200525 \nL 230.087727 102.046125 \nL 229.326818 101.321325 \nL 228.565909 101.200525 \nL 227.805 102.287725 \nL 227.044091 102.408525 \nL 226.283182 102.650125 \nL 225.522273 103.495725 \nL 224.761364 104.582925 \nL 224.000455 106.032525 \nL 223.239545 104.582925 \nL 222.478636 103.978925 \nL 221.717727 104.824525 \nL 220.956818 104.703725 \nL 220.195909 104.703725 \nL 219.435 103.012525 \nL 218.674091 102.770925 \nL 217.913182 103.858125 \nL 217.152273 104.341325 \nL 216.391364 103.737325 \nL 215.630455 104.462125 \nL 214.869545 105.307725 \nL 214.108636 105.670125 \nL 213.347727 106.878125 \nL 212.586818 106.153325 \nL 211.825909 107.240525 \nL 211.065 107.723725 \nL 210.304091 108.206925 \nL 209.543182 108.327725 \nL 208.782273 107.240525 \nL 208.021364 107.965325 \nL 207.260455 109.535725 \nL 206.499545 110.139725 \nL 205.738636 109.052525 \nL 204.977727 109.052525 \nL 204.216818 109.052525 \nL 203.455909 109.052525 \nL 202.695 109.777325 \nL 201.934091 111.468525 \nL 201.173182 110.985325 \nL 200.412273 111.106125 \nL 199.651364 112.797325 \nL 198.890455 114.126125 \nL 198.129545 115.213325 \nL 197.368636 116.421325 \nL 196.607727 116.421325 \nL 195.846818 117.870925 \nL 195.085909 117.750125 \nL 194.325 116.783725 \nL 193.564091 116.058925 \nL 192.803182 116.179725 \nL 192.042273 116.179725 \nL 191.281364 116.058925 \nL 190.520455 115.334125 \nL 189.759545 115.696525 \nL 188.998636 117.266925 \nL 188.237727 117.508525 \nL 187.476818 118.233325 \nL 186.715909 117.629325 \nL 185.955 117.025325 \nL 185.194091 117.508525 \nL 184.433182 117.508525 \nL 183.672273 117.991725 \nL 182.911364 118.233325 \nL 182.150455 117.991725 \nL 181.389545 118.474925 \nL 180.628636 118.958125 \nL 179.867727 119.803725 \nL 179.106818 120.770125 \nL 178.345909 121.978125 \nL 177.585 123.427725 \nL 176.824091 123.548525 \nL 176.063182 124.031725 \nL 175.302273 124.635725 \nL 174.541364 124.514925 \nL 173.780455 124.394125 \nL 173.019545 124.635725 \nL 172.258636 125.481325 \nL 171.497727 126.447725 \nL 170.736818 126.810125 \nL 169.975909 127.172525 \nL 169.215 127.051725 \nL 168.454091 125.964525 \nL 167.693182 127.051725 \nL 166.932273 127.293325 \nL 166.171364 127.897325 \nL 165.410455 127.897325 \nL 164.649545 127.897325 \nL 163.888636 128.984525 \nL 163.127727 128.622125 \nL 162.366818 128.259725 \nL 161.605909 128.622125 \nL 160.845 129.105325 \nL 160.084091 129.105325 \nL 159.323182 129.467725 \nL 158.562273 129.226125 \nL 157.801364 129.346925 \nL 157.040455 129.830125 \nL 156.279545 130.313325 \nL 155.518636 130.313325 \nL 154.757727 130.434125 \nL 153.996818 129.950925 \nL 153.235909 131.762925 \nL 152.475 132.729325 \nL 151.714091 133.695725 \nL 150.953182 133.816525 \nL 150.192273 134.662125 \nL 149.431364 134.662125 \nL 148.670455 135.507725 \nL 147.909545 136.353325 \nL 147.148636 136.957325 \nL 146.387727 137.561325 \nL 145.626818 138.890125 \nL 144.865909 139.735725 \nL 144.105 140.460525 \nL 143.344091 141.668525 \nL 142.583182 142.272525 \nL 141.822273 141.668525 \nL 141.061364 141.789325 \nL 140.300455 142.634925 \nL 139.539545 143.480525 \nL 138.778636 143.238925 \nL 138.017727 143.238925 \nL 137.256818 142.997325 \nL 136.495909 144.567725 \nL 135.735 144.688525 \nL 134.974091 145.534125 \nL 134.213182 146.017325 \nL 133.452273 146.379725 \nL 132.691364 146.862925 \nL 131.930455 146.862925 \nL 131.169545 146.621325 \nL 130.408636 146.983725 \nL 129.647727 149.037325 \nL 128.886818 150.728525 \nL 128.125909 151.936525 \nL 127.365 151.815725 \nL 126.604091 152.178125 \nL 125.843182 151.936525 \nL 125.082273 152.661325 \nL 124.321364 152.540525 \nL 123.560455 152.902925 \nL 122.799545 153.386125 \nL 122.038636 153.990125 \nL 121.277727 153.869325 \nL 120.516818 154.714925 \nL 119.755909 154.594125 \nL 118.995 156.043725 \nL 118.234091 157.010125 \nL 117.473182 158.097325 \nL 116.712273 158.218125 \nL 115.951364 159.426125 \nL 115.190455 160.392525 \nL 114.429545 161.117325 \nL 113.668636 161.479725 \nL 112.907727 161.600525 \nL 112.146818 161.962925 \nL 111.385909 162.566925 \nL 110.625 163.291725 \nL 109.864091 164.258125 \nL 109.103182 164.982925 \nL 108.342273 166.311725 \nL 107.581364 167.640525 \nL 106.820455 168.244525 \nL 106.059545 168.848525 \nL 105.298636 170.056525 \nL 104.537727 170.902125 \nL 103.776818 171.868525 \nL 103.015909 172.230925 \nL 102.255 172.472525 \nL 101.494091 173.076525 \nL 100.733182 173.801325 \nL 99.972273 174.042925 \nL 99.211364 174.888525 \nL 98.450455 175.371725 \nL 97.689545 176.579725 \nL 96.928636 177.304525 \nL 96.167727 177.787725 \nL 95.406818 178.029325 \nL 94.645909 178.995725 \nL 93.885 179.358125 \nL 93.124091 181.049325 \nL 92.363182 182.257325 \nL 91.602273 182.861325 \nL 90.841364 183.465325 \nL 90.080455 185.035725 \nL 89.319545 185.760525 \nL 88.558636 186.726925 \nL 87.797727 187.693325 \nL 87.036818 189.384525 \nL 86.275909 190.592525 \nL 85.515 191.800525 \nL 84.754091 192.887725 \nL 83.993182 193.733325 \nL 83.232273 194.578925 \nL 82.471364 195.303725 \nL 81.710455 196.149325 \nL 80.949545 197.236525 \nL 80.188636 197.961325 \nL 79.427727 198.927725 \nL 78.666818 199.652525 \nL 77.905909 201.102125 \nL 77.145 200.860525 \nL 76.384091 201.706125 \nL 75.623182 202.430925 \nL 74.862273 203.034925 \nL 74.101364 203.397325 \nL 73.340455 204.726125 \nL 72.579545 204.605325 \nL 71.818636 204.605325 \nL 71.057727 205.330125 \nL 70.296818 206.175725 \nL 69.535909 206.538125 \nL 68.775 207.021325 \nL 68.014091 208.229325 \nL 67.253182 209.316525 \nL 66.492273 210.886925 \nL 65.731364 212.215725 \nL 64.970455 213.544525 \nL 64.209545 214.510925 \nL 63.448636 214.631725 \nL 62.687727 215.235725 \nL 61.926818 216.081325 \nL 61.165909 217.289325 \nL 60.405 217.410125 \nL 59.644091 218.014125 \nL 58.883182 218.738925 \nL 58.122273 219.101325 \nL 57.361364 219.705325 \nL 56.600455 220.430125 \nL 55.839545 221.154925 \nL 55.078636 222.483725 \nL 54.317727 223.208525 \nL 53.556818 223.450125 \nL 52.795909 223.691725 \nL 52.035 224.054125 \nL 51.274091 224.778925 \nL 50.513182 225.503725 \nL 49.752273 225.866125 \nL 48.991364 226.711725 \nL 48.230455 227.919725 \nL 47.469545 228.161325 \nL 46.708636 228.282125 \nL 45.947727 228.402925 \nL 45.186818 228.765325 \nL 44.425909 229.006925 \nL 43.665 229.731725 \nL 42.904091 230.094125 \nL 42.143182 230.818925 \nz\n\" style=\"fill:#1f77b4;fill-opacity:0.1;\"/>\n   </g>\n   <g id=\"PolyCollection_2\">\n    <path clip-path=\"url(#p8207875bcf)\" d=\"M 42.143182 226.107725 \nL 42.143182 211.490925 \nL 42.904091 210.886925 \nL 43.665 210.041325 \nL 44.425909 209.437325 \nL 45.186818 208.833325 \nL 45.947727 208.712525 \nL 46.708636 207.866925 \nL 47.469545 207.383725 \nL 48.230455 206.779725 \nL 48.991364 206.779725 \nL 49.752273 206.175725 \nL 50.513182 204.967725 \nL 51.274091 204.242925 \nL 52.035 203.276525 \nL 52.795909 202.189325 \nL 53.556818 201.706125 \nL 54.317727 200.981325 \nL 55.078636 200.739725 \nL 55.839545 199.773325 \nL 56.600455 198.927725 \nL 57.361364 197.840525 \nL 58.122273 197.719725 \nL 58.883182 197.236525 \nL 59.644091 196.994925 \nL 60.405 196.390925 \nL 61.165909 195.062125 \nL 61.926818 194.095725 \nL 62.687727 193.129325 \nL 63.448636 191.800525 \nL 64.209545 191.196525 \nL 64.970455 191.317325 \nL 65.731364 190.834125 \nL 66.492273 190.109325 \nL 67.253182 189.988525 \nL 68.014091 189.384525 \nL 68.775 188.901325 \nL 69.535909 187.572525 \nL 70.296818 186.847725 \nL 71.057727 186.243725 \nL 71.818636 184.794125 \nL 72.579545 183.586125 \nL 73.340455 182.740525 \nL 74.101364 182.136525 \nL 74.862273 181.774125 \nL 75.623182 180.324525 \nL 76.384091 180.566125 \nL 77.145 179.478925 \nL 77.905909 177.546125 \nL 78.666818 175.975725 \nL 79.427727 175.613325 \nL 80.188636 175.250925 \nL 80.949545 175.734125 \nL 81.710455 174.767725 \nL 82.471364 174.646925 \nL 83.232273 174.042925 \nL 83.993182 172.714125 \nL 84.754091 171.747725 \nL 85.515 170.660525 \nL 86.275909 168.969325 \nL 87.036818 167.761325 \nL 87.797727 166.915725 \nL 88.558636 166.553325 \nL 89.319545 165.828525 \nL 90.080455 164.862125 \nL 90.841364 163.895725 \nL 91.602273 163.050125 \nL 92.363182 162.325325 \nL 93.124091 160.754925 \nL 93.885 159.305325 \nL 94.645909 159.063725 \nL 95.406818 158.097325 \nL 96.167727 158.338925 \nL 96.928636 158.338925 \nL 97.689545 158.580525 \nL 98.450455 157.855725 \nL 99.211364 157.734925 \nL 99.972273 157.855725 \nL 100.733182 158.338925 \nL 101.494091 156.768525 \nL 102.255 155.439725 \nL 103.015909 155.198125 \nL 103.776818 154.352525 \nL 104.537727 154.352525 \nL 105.298636 153.748525 \nL 106.059545 152.902925 \nL 106.820455 153.506925 \nL 107.581364 152.902925 \nL 108.342273 152.057325 \nL 109.103182 150.970125 \nL 109.864091 150.124525 \nL 110.625 148.916525 \nL 111.385909 147.950125 \nL 112.146818 148.070925 \nL 112.907727 148.433325 \nL 113.668636 148.191725 \nL 114.429545 147.829325 \nL 115.190455 147.104525 \nL 115.951364 145.654925 \nL 116.712273 145.534125 \nL 117.473182 145.413325 \nL 118.234091 144.205325 \nL 118.995 142.997325 \nL 119.755909 142.393325 \nL 120.516818 142.876525 \nL 121.277727 142.151725 \nL 122.038636 140.218925 \nL 122.799545 139.131725 \nL 123.560455 138.286125 \nL 124.321364 137.319725 \nL 125.082273 137.198925 \nL 125.843182 136.715725 \nL 126.604091 136.353325 \nL 127.365 135.507725 \nL 128.125909 135.386925 \nL 128.886818 135.990925 \nL 129.647727 135.266125 \nL 130.408636 134.662125 \nL 131.169545 132.970925 \nL 131.930455 131.883725 \nL 132.691364 131.400525 \nL 133.452273 130.434125 \nL 134.213182 129.226125 \nL 134.974091 128.259725 \nL 135.735 127.655725 \nL 136.495909 127.293325 \nL 137.256818 126.447725 \nL 138.017727 126.326925 \nL 138.778636 126.085325 \nL 139.539545 125.602125 \nL 140.300455 125.360525 \nL 141.061364 124.998125 \nL 141.822273 124.152525 \nL 142.583182 122.944525 \nL 143.344091 122.944525 \nL 144.105 122.582125 \nL 144.865909 121.253325 \nL 145.626818 121.132525 \nL 146.387727 120.045325 \nL 147.148636 119.078925 \nL 147.909545 118.716525 \nL 148.670455 118.233325 \nL 149.431364 116.662925 \nL 150.192273 115.213325 \nL 150.953182 114.971725 \nL 151.714091 114.850925 \nL 152.475 113.763725 \nL 153.235909 113.280525 \nL 153.996818 113.280525 \nL 154.757727 112.918125 \nL 155.518636 112.193325 \nL 156.279545 111.830925 \nL 157.040455 110.381325 \nL 157.801364 110.260525 \nL 158.562273 109.535725 \nL 159.323182 109.535725 \nL 160.084091 110.018925 \nL 160.845 108.931725 \nL 161.605909 108.569325 \nL 162.366818 108.931725 \nL 163.127727 109.294125 \nL 163.888636 108.931725 \nL 164.649545 108.327725 \nL 165.410455 108.327725 \nL 166.171364 107.844525 \nL 166.932273 107.723725 \nL 167.693182 106.757325 \nL 168.454091 106.394925 \nL 169.215 106.878125 \nL 169.975909 108.206925 \nL 170.736818 106.394925 \nL 171.497727 107.240525 \nL 172.258636 106.998925 \nL 173.019545 105.670125 \nL 173.780455 104.462125 \nL 174.541364 104.462125 \nL 175.302273 104.824525 \nL 176.063182 102.891725 \nL 176.824091 101.200525 \nL 177.585 101.925325 \nL 178.345909 102.408525 \nL 179.106818 100.596525 \nL 179.867727 99.992525 \nL 180.628636 99.267725 \nL 181.389545 97.938925 \nL 182.150455 97.576525 \nL 182.911364 95.885325 \nL 183.672273 94.918925 \nL 184.433182 94.435725 \nL 185.194091 96.126925 \nL 185.955 96.006125 \nL 186.715909 96.489325 \nL 187.476818 96.368525 \nL 188.237727 95.039725 \nL 188.998636 94.677325 \nL 189.759545 93.469325 \nL 190.520455 92.865325 \nL 191.281364 92.261325 \nL 192.042273 92.261325 \nL 192.803182 91.778125 \nL 193.564091 91.294925 \nL 194.325 91.053325 \nL 195.085909 91.053325 \nL 195.846818 90.690925 \nL 196.607727 89.724525 \nL 197.368636 90.328525 \nL 198.129545 90.086925 \nL 198.890455 90.207725 \nL 199.651364 89.362125 \nL 200.412273 88.999725 \nL 201.173182 87.670925 \nL 201.934091 87.187725 \nL 202.695 87.912525 \nL 203.455909 88.033325 \nL 204.216818 87.429325 \nL 204.977727 86.583725 \nL 205.738636 86.946125 \nL 206.499545 86.221325 \nL 207.260455 86.825325 \nL 208.021364 87.429325 \nL 208.782273 87.308525 \nL 209.543182 88.274925 \nL 210.304091 88.033325 \nL 211.065 88.154125 \nL 211.825909 86.946125 \nL 212.586818 86.221325 \nL 213.347727 86.462925 \nL 214.108636 86.100525 \nL 214.869545 85.738125 \nL 215.630455 86.342125 \nL 216.391364 85.375725 \nL 217.152273 83.926125 \nL 217.913182 83.322125 \nL 218.674091 83.563725 \nL 219.435 82.234925 \nL 220.195909 81.630925 \nL 220.956818 81.389325 \nL 221.717727 81.872525 \nL 222.478636 81.872525 \nL 223.239545 82.114125 \nL 224.000455 81.630925 \nL 224.761364 82.114125 \nL 225.522273 83.322125 \nL 226.283182 83.442925 \nL 227.044091 82.959725 \nL 227.805 83.684525 \nL 228.565909 83.442925 \nL 229.326818 83.563725 \nL 230.087727 85.134125 \nL 230.848636 85.134125 \nL 231.609545 85.254925 \nL 232.370455 85.254925 \nL 233.131364 85.134125 \nL 233.892273 85.013325 \nL 234.653182 84.892525 \nL 235.414091 85.254925 \nL 236.175 84.771725 \nL 236.935909 84.771725 \nL 237.696818 85.013325 \nL 238.457727 84.892525 \nL 239.218636 84.771725 \nL 239.979545 84.530125 \nL 240.740455 84.530125 \nL 241.501364 83.684525 \nL 242.262273 83.442925 \nL 243.023182 82.959725 \nL 243.784091 83.563725 \nL 244.545 83.684525 \nL 245.305909 82.959725 \nL 246.066818 82.114125 \nL 246.827727 83.563725 \nL 247.588636 83.201325 \nL 248.349545 82.838925 \nL 249.110455 83.563725 \nL 249.871364 83.080525 \nL 250.632273 83.442925 \nL 251.393182 81.630925 \nL 252.154091 81.630925 \nL 252.915 81.510125 \nL 253.675909 80.543725 \nL 254.436818 80.181325 \nL 255.197727 81.268525 \nL 255.958636 81.630925 \nL 256.719545 81.751725 \nL 257.480455 82.959725 \nL 258.241364 82.597325 \nL 259.002273 82.718125 \nL 259.763182 82.355725 \nL 260.524091 82.718125 \nL 261.285 81.993325 \nL 262.045909 81.993325 \nL 262.806818 81.389325 \nL 263.567727 81.510125 \nL 264.328636 81.872525 \nL 265.089545 81.630925 \nL 265.850455 81.872525 \nL 266.611364 82.718125 \nL 267.372273 83.080525 \nL 268.133182 83.322125 \nL 268.894091 82.718125 \nL 269.655 83.080525 \nL 270.415909 84.409325 \nL 271.176818 84.530125 \nL 271.937727 85.375725 \nL 272.698636 85.134125 \nL 273.459545 83.684525 \nL 274.220455 83.805325 \nL 274.981364 82.838925 \nL 275.742273 83.080525 \nL 276.503182 83.080525 \nL 277.264091 84.288525 \nL 278.025 82.597325 \nL 278.785909 82.476525 \nL 279.546818 80.785325 \nL 280.307727 80.060525 \nL 281.068636 79.094125 \nL 281.829545 79.577325 \nL 282.590455 78.731725 \nL 283.351364 77.644525 \nL 284.112273 76.798925 \nL 284.873182 76.436525 \nL 285.634091 76.315725 \nL 286.395 75.228525 \nL 287.155909 75.953325 \nL 287.916818 74.262125 \nL 288.677727 73.174925 \nL 289.438636 72.329325 \nL 290.199545 72.570925 \nL 290.960455 74.020525 \nL 291.721364 73.778925 \nL 292.482273 74.624525 \nL 293.243182 74.141325 \nL 294.004091 73.416525 \nL 294.765 73.416525 \nL 295.525909 72.570925 \nL 296.286818 72.691725 \nL 297.047727 72.812525 \nL 297.808636 73.174925 \nL 298.569545 73.658125 \nL 299.330455 73.416525 \nL 300.091364 73.174925 \nL 300.852273 73.295725 \nL 301.613182 72.691725 \nL 302.374091 71.604525 \nL 303.135 72.570925 \nL 303.895909 73.295725 \nL 304.656818 72.812525 \nL 305.417727 74.141325 \nL 306.178636 74.262125 \nL 306.939545 75.349325 \nL 307.700455 74.866125 \nL 308.461364 74.503725 \nL 309.222273 74.866125 \nL 309.983182 75.228525 \nL 310.744091 74.020525 \nL 311.505 74.141325 \nL 312.265909 74.262125 \nL 313.026818 74.020525 \nL 313.787727 73.295725 \nL 314.548636 74.262125 \nL 315.309545 74.020525 \nL 316.070455 74.503725 \nL 316.831364 74.020525 \nL 317.592273 73.416525 \nL 318.353182 72.208525 \nL 319.114091 72.570925 \nL 319.875 72.087725 \nL 320.635909 71.483725 \nL 321.396818 71.483725 \nL 322.157727 71.000525 \nL 322.918636 72.208525 \nL 323.679545 72.691725 \nL 324.440455 71.604525 \nL 325.201364 73.416525 \nL 325.962273 73.054125 \nL 326.723182 72.933325 \nL 327.484091 74.745325 \nL 328.245 75.107725 \nL 329.005909 75.832525 \nL 329.766818 75.953325 \nL 330.527727 76.194925 \nL 331.288636 76.074125 \nL 332.049545 75.953325 \nL 332.810455 76.798925 \nL 333.571364 77.040525 \nL 334.332273 77.765325 \nL 335.093182 78.369325 \nL 335.854091 78.127725 \nL 336.615 80.302125 \nL 337.375909 79.818925 \nL 338.136818 79.456525 \nL 338.897727 79.577325 \nL 339.658636 79.698125 \nL 340.419545 79.818925 \nL 341.180455 79.939725 \nL 341.941364 79.335725 \nL 342.702273 79.335725 \nL 343.463182 78.610925 \nL 344.224091 78.369325 \nL 344.985 79.214925 \nL 345.745909 78.852525 \nL 346.506818 79.456525 \nL 346.506818 85.496525 \nL 346.506818 85.496525 \nL 345.745909 86.946125 \nL 344.985 87.308525 \nL 344.224091 86.946125 \nL 343.463182 87.187725 \nL 342.702273 87.550125 \nL 341.941364 88.154125 \nL 341.180455 87.429325 \nL 340.419545 87.429325 \nL 339.658636 87.066925 \nL 338.897727 87.187725 \nL 338.136818 85.617325 \nL 337.375909 86.462925 \nL 336.615 86.583725 \nL 335.854091 86.825325 \nL 335.093182 85.738125 \nL 334.332273 85.617325 \nL 333.571364 85.013325 \nL 332.810455 84.409325 \nL 332.049545 84.409325 \nL 331.288636 84.892525 \nL 330.527727 85.617325 \nL 329.766818 85.254925 \nL 329.005909 84.892525 \nL 328.245 85.254925 \nL 327.484091 85.254925 \nL 326.723182 85.013325 \nL 325.962273 86.462925 \nL 325.201364 86.342125 \nL 324.440455 87.550125 \nL 323.679545 87.791725 \nL 322.918636 88.999725 \nL 322.157727 90.207725 \nL 321.396818 88.999725 \nL 320.635909 88.999725 \nL 319.875 89.241325 \nL 319.114091 89.362125 \nL 318.353182 89.603725 \nL 317.592273 89.241325 \nL 316.831364 88.878925 \nL 316.070455 89.482925 \nL 315.309545 88.033325 \nL 314.548636 88.878925 \nL 313.787727 89.362125 \nL 313.026818 89.482925 \nL 312.265909 89.120525 \nL 311.505 89.120525 \nL 310.744091 90.811725 \nL 309.983182 90.932525 \nL 309.222273 91.053325 \nL 308.461364 91.294925 \nL 307.700455 91.778125 \nL 306.939545 92.502925 \nL 306.178636 91.778125 \nL 305.417727 92.986125 \nL 304.656818 92.382125 \nL 303.895909 91.898925 \nL 303.135 91.657325 \nL 302.374091 90.570125 \nL 301.613182 89.120525 \nL 300.852273 88.516525 \nL 300.091364 88.758125 \nL 299.330455 88.758125 \nL 298.569545 88.758125 \nL 297.808636 88.516525 \nL 297.047727 89.482925 \nL 296.286818 88.516525 \nL 295.525909 88.395725 \nL 294.765 88.274925 \nL 294.004091 88.637325 \nL 293.243182 88.758125 \nL 292.482273 88.516525 \nL 291.721364 88.516525 \nL 290.960455 89.241325 \nL 290.199545 88.033325 \nL 289.438636 88.274925 \nL 288.677727 87.791725 \nL 287.916818 88.154125 \nL 287.155909 88.274925 \nL 286.395 88.516525 \nL 285.634091 88.154125 \nL 284.873182 88.154125 \nL 284.112273 87.187725 \nL 283.351364 86.825325 \nL 282.590455 87.429325 \nL 281.829545 85.979725 \nL 281.068636 85.738125 \nL 280.307727 84.892525 \nL 279.546818 84.650925 \nL 278.785909 85.496525 \nL 278.025 85.979725 \nL 277.264091 85.858925 \nL 276.503182 85.979725 \nL 275.742273 85.134125 \nL 274.981364 84.530125 \nL 274.220455 84.167725 \nL 273.459545 85.013325 \nL 272.698636 85.496525 \nL 271.937727 86.100525 \nL 271.176818 85.979725 \nL 270.415909 87.308525 \nL 269.655 88.033325 \nL 268.894091 87.912525 \nL 268.133182 88.395725 \nL 267.372273 88.878925 \nL 266.611364 88.395725 \nL 265.850455 88.516525 \nL 265.089545 88.999725 \nL 264.328636 89.482925 \nL 263.567727 89.603725 \nL 262.806818 89.966125 \nL 262.045909 90.449325 \nL 261.285 90.932525 \nL 260.524091 90.932525 \nL 259.763182 92.382125 \nL 259.002273 92.744525 \nL 258.241364 93.952525 \nL 257.480455 93.106925 \nL 256.719545 93.831725 \nL 255.958636 94.556525 \nL 255.197727 95.281325 \nL 254.436818 97.334925 \nL 253.675909 97.334925 \nL 252.915 96.851725 \nL 252.154091 97.334925 \nL 251.393182 98.422125 \nL 250.632273 98.180525 \nL 249.871364 98.422125 \nL 249.110455 97.818125 \nL 248.349545 99.509325 \nL 247.588636 98.784525 \nL 246.827727 99.026125 \nL 246.066818 100.234125 \nL 245.305909 99.630125 \nL 244.545 100.354925 \nL 243.784091 100.113325 \nL 243.023182 100.234125 \nL 242.262273 100.475725 \nL 241.501364 100.354925 \nL 240.740455 99.388525 \nL 239.979545 99.146925 \nL 239.218636 99.388525 \nL 238.457727 99.267725 \nL 237.696818 99.509325 \nL 236.935909 99.630125 \nL 236.175 98.905325 \nL 235.414091 98.422125 \nL 234.653182 97.334925 \nL 233.892273 96.610125 \nL 233.131364 97.697325 \nL 232.370455 98.180525 \nL 231.609545 98.905325 \nL 230.848636 98.422125 \nL 230.087727 100.596525 \nL 229.326818 101.079725 \nL 228.565909 101.079725 \nL 227.805 100.717325 \nL 227.044091 101.804525 \nL 226.283182 101.925325 \nL 225.522273 101.321325 \nL 224.761364 101.321325 \nL 224.000455 102.287725 \nL 223.239545 102.650125 \nL 222.478636 103.616525 \nL 221.717727 103.616525 \nL 220.956818 104.462125 \nL 220.195909 105.307725 \nL 219.435 106.757325 \nL 218.674091 106.153325 \nL 217.913182 106.032525 \nL 217.152273 105.186925 \nL 216.391364 105.066125 \nL 215.630455 105.428525 \nL 214.869545 106.757325 \nL 214.108636 107.723725 \nL 213.347727 107.723725 \nL 212.586818 107.240525 \nL 211.825909 106.636525 \nL 211.065 106.153325 \nL 210.304091 107.119725 \nL 209.543182 107.119725 \nL 208.782273 107.361325 \nL 208.021364 109.052525 \nL 207.260455 109.535725 \nL 206.499545 110.018925 \nL 205.738636 109.535725 \nL 204.977727 111.468525 \nL 204.216818 112.193325 \nL 203.455909 111.710125 \nL 202.695 111.226925 \nL 201.934091 110.381325 \nL 201.173182 110.381325 \nL 200.412273 111.589325 \nL 199.651364 111.347725 \nL 198.890455 112.676525 \nL 198.129545 113.038925 \nL 197.368636 113.763725 \nL 196.607727 115.213325 \nL 195.846818 116.421325 \nL 195.085909 115.575725 \nL 194.325 116.421325 \nL 193.564091 116.421325 \nL 192.803182 117.025325 \nL 192.042273 117.387725 \nL 191.281364 117.025325 \nL 190.520455 118.474925 \nL 189.759545 119.320525 \nL 188.998636 119.803725 \nL 188.237727 120.528525 \nL 187.476818 121.615725 \nL 186.715909 121.857325 \nL 185.955 122.702925 \nL 185.194091 122.340525 \nL 184.433182 122.219725 \nL 183.672273 122.340525 \nL 182.911364 123.065325 \nL 182.150455 123.306925 \nL 181.389545 124.394125 \nL 180.628636 124.152525 \nL 179.867727 124.756525 \nL 179.106818 125.360525 \nL 178.345909 125.360525 \nL 177.585 125.964525 \nL 176.824091 127.293325 \nL 176.063182 128.138925 \nL 175.302273 128.259725 \nL 174.541364 128.984525 \nL 173.780455 129.588525 \nL 173.019545 130.796525 \nL 172.258636 129.467725 \nL 171.497727 129.709325 \nL 170.736818 129.105325 \nL 169.975909 128.984525 \nL 169.215 129.588525 \nL 168.454091 130.796525 \nL 167.693182 130.554925 \nL 166.932273 129.830125 \nL 166.171364 129.709325 \nL 165.410455 129.467725 \nL 164.649545 129.830125 \nL 163.888636 130.796525 \nL 163.127727 131.279725 \nL 162.366818 131.400525 \nL 161.605909 131.762925 \nL 160.845 133.212525 \nL 160.084091 133.695725 \nL 159.323182 135.628525 \nL 158.562273 135.870125 \nL 157.801364 136.353325 \nL 157.040455 136.474125 \nL 156.279545 137.198925 \nL 155.518636 137.319725 \nL 154.757727 138.527725 \nL 153.996818 137.561325 \nL 153.235909 138.648525 \nL 152.475 139.735725 \nL 151.714091 139.494125 \nL 150.953182 139.977325 \nL 150.192273 141.547725 \nL 149.431364 142.393325 \nL 148.670455 143.842925 \nL 147.909545 143.963725 \nL 147.148636 143.963725 \nL 146.387727 144.567725 \nL 145.626818 145.171725 \nL 144.865909 146.138125 \nL 144.105 146.862925 \nL 143.344091 147.829325 \nL 142.583182 148.916525 \nL 141.822273 150.366125 \nL 141.061364 152.782125 \nL 140.300455 153.265325 \nL 139.539545 154.352525 \nL 138.778636 154.473325 \nL 138.017727 155.198125 \nL 137.256818 155.922925 \nL 136.495909 157.130925 \nL 135.735 157.493325 \nL 134.974091 157.976525 \nL 134.213182 158.459725 \nL 133.452273 158.822125 \nL 132.691364 159.426125 \nL 131.930455 158.942925 \nL 131.169545 159.546925 \nL 130.408636 159.546925 \nL 129.647727 160.030125 \nL 128.886818 159.788525 \nL 128.125909 160.513325 \nL 127.365 160.996525 \nL 126.604091 161.238125 \nL 125.843182 161.842125 \nL 125.082273 161.962925 \nL 124.321364 161.962925 \nL 123.560455 163.050125 \nL 122.799545 163.170925 \nL 122.038636 163.533325 \nL 121.277727 163.533325 \nL 120.516818 164.137325 \nL 119.755909 165.103725 \nL 118.995 167.157325 \nL 118.234091 167.519725 \nL 117.473182 168.606925 \nL 116.712273 169.694125 \nL 115.951364 170.418925 \nL 115.190455 171.868525 \nL 114.429545 171.868525 \nL 113.668636 172.351725 \nL 112.907727 173.318125 \nL 112.146818 173.559725 \nL 111.385909 174.284525 \nL 110.625 175.734125 \nL 109.864091 176.217325 \nL 109.103182 177.425325 \nL 108.342273 178.754125 \nL 107.581364 179.116525 \nL 106.820455 179.358125 \nL 106.059545 180.445325 \nL 105.298636 181.170125 \nL 104.537727 182.619725 \nL 103.776818 183.465325 \nL 103.015909 184.069325 \nL 102.255 183.948525 \nL 101.494091 184.673325 \nL 100.733182 185.156525 \nL 99.972273 184.552525 \nL 99.211364 185.518925 \nL 98.450455 186.364525 \nL 97.689545 186.968525 \nL 96.928636 187.814125 \nL 96.167727 189.505325 \nL 95.406818 190.592525 \nL 94.645909 191.679725 \nL 93.885 192.162925 \nL 93.124091 192.887725 \nL 92.363182 193.129325 \nL 91.602273 194.458125 \nL 90.841364 195.424525 \nL 90.080455 196.753325 \nL 89.319545 197.719725 \nL 88.558636 198.565325 \nL 87.797727 199.048525 \nL 87.036818 199.894125 \nL 86.275909 200.981325 \nL 85.515 202.189325 \nL 84.754091 201.826925 \nL 83.993182 203.276525 \nL 83.232273 203.638925 \nL 82.471364 204.967725 \nL 81.710455 206.296525 \nL 80.949545 207.021325 \nL 80.188636 207.987725 \nL 79.427727 208.470925 \nL 78.666818 208.712525 \nL 77.905909 209.678925 \nL 77.145 209.799725 \nL 76.384091 210.282925 \nL 75.623182 211.611725 \nL 74.862273 211.974125 \nL 74.101364 211.853325 \nL 73.340455 211.974125 \nL 72.579545 212.336525 \nL 71.818636 212.457325 \nL 71.057727 213.423725 \nL 70.296818 213.302925 \nL 69.535909 214.631725 \nL 68.775 214.631725 \nL 68.014091 214.994125 \nL 67.253182 214.752525 \nL 66.492273 215.114925 \nL 65.731364 215.718925 \nL 64.970455 215.960525 \nL 64.209545 216.926925 \nL 63.448636 217.168525 \nL 62.687727 217.047725 \nL 61.926818 216.806125 \nL 61.165909 217.651725 \nL 60.405 217.651725 \nL 59.644091 218.376525 \nL 58.883182 218.859725 \nL 58.122273 218.980525 \nL 57.361364 219.584525 \nL 56.600455 220.309325 \nL 55.839545 221.154925 \nL 55.078636 221.275725 \nL 54.317727 221.275725 \nL 53.556818 221.758925 \nL 52.795909 222.362925 \nL 52.035 222.604525 \nL 51.274091 223.087725 \nL 50.513182 223.329325 \nL 49.752273 223.812525 \nL 48.991364 224.295725 \nL 48.230455 224.537325 \nL 47.469545 224.537325 \nL 46.708636 225.262125 \nL 45.947727 225.262125 \nL 45.186818 225.624525 \nL 44.425909 225.745325 \nL 43.665 226.107725 \nL 42.904091 225.986925 \nL 42.143182 226.107725 \nz\n\" style=\"fill:#ff7f0e;fill-opacity:0.1;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m3f1642fa8f\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.143182\" xlink:href=\"#m3f1642fa8f\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 100 -->\n      <g transform=\"translate(32.599432 254.356562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"118.234091\" xlink:href=\"#m3f1642fa8f\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 200 -->\n      <g transform=\"translate(108.690341 254.356562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"194.325\" xlink:href=\"#m3f1642fa8f\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 300 -->\n      <g transform=\"translate(184.78125 254.356562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"270.415909\" xlink:href=\"#m3f1642fa8f\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 400 -->\n      <g transform=\"translate(260.872159 254.356562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"346.506818\" xlink:href=\"#m3f1642fa8f\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 500 -->\n      <g transform=\"translate(336.963068 254.356562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_6\">\n     <!-- Number of episodes -->\n     <g transform=\"translate(144.082031 268.034687)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 9.8125 72.90625 \nL 23.09375 72.90625 \nL 55.421875 11.921875 \nL 55.421875 72.90625 \nL 64.984375 72.90625 \nL 64.984375 0 \nL 51.703125 0 \nL 19.390625 60.984375 \nL 19.390625 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-78\"/>\n       <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n       <path d=\"M 52 44.1875 \nQ 55.375 50.25 60.0625 53.125 \nQ 64.75 56 71.09375 56 \nQ 79.640625 56 84.28125 50.015625 \nQ 88.921875 44.046875 88.921875 33.015625 \nL 88.921875 0 \nL 79.890625 0 \nL 79.890625 32.71875 \nQ 79.890625 40.578125 77.09375 44.375 \nQ 74.3125 48.1875 68.609375 48.1875 \nQ 61.625 48.1875 57.5625 43.546875 \nQ 53.515625 38.921875 53.515625 30.90625 \nL 53.515625 0 \nL 44.484375 0 \nL 44.484375 32.71875 \nQ 44.484375 40.625 41.703125 44.40625 \nQ 38.921875 48.1875 33.109375 48.1875 \nQ 26.21875 48.1875 22.15625 43.53125 \nQ 18.109375 38.875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.1875 51.21875 25.484375 53.609375 \nQ 29.78125 56 35.6875 56 \nQ 41.65625 56 45.828125 52.96875 \nQ 50 49.953125 52 44.1875 \nz\n\" id=\"DejaVuSans-109\"/>\n       <path d=\"M 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\nM 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nz\n\" id=\"DejaVuSans-98\"/>\n       <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n       <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n       <path id=\"DejaVuSans-32\"/>\n       <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n       <path d=\"M 37.109375 75.984375 \nL 37.109375 68.5 \nL 28.515625 68.5 \nQ 23.6875 68.5 21.796875 66.546875 \nQ 19.921875 64.59375 19.921875 59.515625 \nL 19.921875 54.6875 \nL 34.71875 54.6875 \nL 34.71875 47.703125 \nL 19.921875 47.703125 \nL 19.921875 0 \nL 10.890625 0 \nL 10.890625 47.703125 \nL 2.296875 47.703125 \nL 2.296875 54.6875 \nL 10.890625 54.6875 \nL 10.890625 58.5 \nQ 10.890625 67.625 15.140625 71.796875 \nQ 19.390625 75.984375 28.609375 75.984375 \nz\n\" id=\"DejaVuSans-102\"/>\n       <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n       <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n       <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n       <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"74.804688\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"138.183594\" xlink:href=\"#DejaVuSans-109\"/>\n      <use x=\"235.595703\" xlink:href=\"#DejaVuSans-98\"/>\n      <use x=\"299.072266\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"360.595703\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"401.708984\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"433.496094\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"494.677734\" xlink:href=\"#DejaVuSans-102\"/>\n      <use x=\"529.882812\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"561.669922\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"623.193359\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"686.669922\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"714.453125\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"766.552734\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"827.734375\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"891.210938\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"952.734375\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_6\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m71d1739b3e\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m71d1739b3e\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0 -->\n      <g transform=\"translate(13.5625 243.557344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m71d1739b3e\" y=\"227.678125\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 1 -->\n      <g transform=\"translate(13.5625 231.477344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m71d1739b3e\" y=\"215.598125\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 2 -->\n      <g transform=\"translate(13.5625 219.397344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m71d1739b3e\" y=\"203.518125\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 3 -->\n      <g transform=\"translate(13.5625 207.317344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m71d1739b3e\" y=\"191.438125\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 4 -->\n      <g transform=\"translate(13.5625 195.237344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m71d1739b3e\" y=\"179.358125\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 5 -->\n      <g transform=\"translate(13.5625 183.157344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m71d1739b3e\" y=\"167.278125\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 6 -->\n      <g transform=\"translate(13.5625 171.077344)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m71d1739b3e\" y=\"155.198125\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 7 -->\n      <g transform=\"translate(13.5625 158.997344)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-55\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m71d1739b3e\" y=\"143.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 8 -->\n      <g transform=\"translate(13.5625 146.917344)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_10\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m71d1739b3e\" y=\"131.038125\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 9 -->\n      <g transform=\"translate(13.5625 134.837344)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.984375 1.515625 \nL 10.984375 10.5 \nQ 14.703125 8.734375 18.5 7.8125 \nQ 22.3125 6.890625 25.984375 6.890625 \nQ 35.75 6.890625 40.890625 13.453125 \nQ 46.046875 20.015625 46.78125 33.40625 \nQ 43.953125 29.203125 39.59375 26.953125 \nQ 35.25 24.703125 29.984375 24.703125 \nQ 19.046875 24.703125 12.671875 31.3125 \nQ 6.296875 37.9375 6.296875 49.421875 \nQ 6.296875 60.640625 12.9375 67.421875 \nQ 19.578125 74.21875 30.609375 74.21875 \nQ 43.265625 74.21875 49.921875 64.515625 \nQ 56.59375 54.828125 56.59375 36.375 \nQ 56.59375 19.140625 48.40625 8.859375 \nQ 40.234375 -1.421875 26.421875 -1.421875 \nQ 22.703125 -1.421875 18.890625 -0.6875 \nQ 15.09375 0.046875 10.984375 1.515625 \nz\nM 30.609375 32.421875 \nQ 37.25 32.421875 41.125 36.953125 \nQ 45.015625 41.5 45.015625 49.421875 \nQ 45.015625 57.28125 41.125 61.84375 \nQ 37.25 66.40625 30.609375 66.40625 \nQ 23.96875 66.40625 20.09375 61.84375 \nQ 16.21875 57.28125 16.21875 49.421875 \nQ 16.21875 41.5 20.09375 36.953125 \nQ 23.96875 32.421875 30.609375 32.421875 \nz\n\" id=\"DejaVuSans-57\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-57\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_11\">\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m71d1739b3e\" y=\"118.958125\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 10 -->\n      <g transform=\"translate(7.2 122.757344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_12\">\n     <g id=\"line2d_17\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m71d1739b3e\" y=\"106.878125\"/>\n      </g>\n     </g>\n     <g id=\"text_18\">\n      <!-- 11 -->\n      <g transform=\"translate(7.2 110.677344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_13\">\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m71d1739b3e\" y=\"94.798125\"/>\n      </g>\n     </g>\n     <g id=\"text_19\">\n      <!-- 12 -->\n      <g transform=\"translate(7.2 98.597344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_14\">\n     <g id=\"line2d_19\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m71d1739b3e\" y=\"82.718125\"/>\n      </g>\n     </g>\n     <g id=\"text_20\">\n      <!-- 13 -->\n      <g transform=\"translate(7.2 86.517344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_15\">\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m71d1739b3e\" y=\"70.638125\"/>\n      </g>\n     </g>\n     <g id=\"text_21\">\n      <!-- 14 -->\n      <g transform=\"translate(7.2 74.437344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_16\">\n     <g id=\"line2d_21\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m71d1739b3e\" y=\"58.558125\"/>\n      </g>\n     </g>\n     <g id=\"text_22\">\n      <!-- 15 -->\n      <g transform=\"translate(7.2 62.357344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_17\">\n     <g id=\"line2d_22\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m71d1739b3e\" y=\"46.478125\"/>\n      </g>\n     </g>\n     <g id=\"text_23\">\n      <!-- 16 -->\n      <g transform=\"translate(7.2 50.277344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_18\">\n     <g id=\"line2d_23\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m71d1739b3e\" y=\"34.398125\"/>\n      </g>\n     </g>\n     <g id=\"text_24\">\n      <!-- 17 -->\n      <g transform=\"translate(7.2 38.197344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_19\">\n     <g id=\"line2d_24\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m71d1739b3e\" y=\"22.318125\"/>\n      </g>\n     </g>\n     <g id=\"text_25\">\n      <!-- 18 -->\n      <g transform=\"translate(7.2 26.117344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_25\">\n    <path clip-path=\"url(#p8207875bcf)\" d=\"M 42.143182 222.362925 \nL 43.665 221.154925 \nL 44.425909 220.248925 \nL 46.708636 218.678525 \nL 47.469545 218.557725 \nL 48.230455 217.712125 \nL 48.991364 216.624925 \nL 49.752273 215.960525 \nL 50.513182 215.718925 \nL 52.795909 213.846525 \nL 53.556818 213.484125 \nL 54.317727 212.880125 \nL 55.078636 211.913725 \nL 55.839545 210.403725 \nL 56.600455 209.799725 \nL 57.361364 208.954125 \nL 58.122273 208.410525 \nL 58.883182 207.685725 \nL 59.644091 207.142125 \nL 61.926818 204.907325 \nL 62.687727 204.363725 \nL 63.448636 204.001325 \nL 64.970455 202.793325 \nL 66.492273 200.256525 \nL 68.014091 198.202925 \nL 68.775 197.659325 \nL 69.535909 196.813725 \nL 72.579545 194.518525 \nL 73.340455 194.337325 \nL 74.101364 193.370925 \nL 74.862273 192.585725 \nL 75.623182 192.102525 \nL 76.384091 191.136125 \nL 77.145 190.411325 \nL 77.905909 190.048925 \nL 78.666818 188.599325 \nL 79.427727 187.391325 \nL 80.188636 186.847725 \nL 80.949545 186.062525 \nL 81.710455 184.673325 \nL 82.471364 183.767325 \nL 83.232273 183.404925 \nL 83.993182 182.257325 \nL 84.754091 181.774125 \nL 85.515 180.445325 \nL 87.036818 178.814525 \nL 87.797727 177.304525 \nL 89.319545 175.311325 \nL 90.841364 173.438925 \nL 93.124091 171.083325 \nL 93.885 169.754525 \nL 94.645909 169.754525 \nL 95.406818 168.667325 \nL 97.689545 166.794925 \nL 98.450455 165.888925 \nL 99.211364 165.284925 \nL 99.972273 164.318525 \nL 100.733182 163.835325 \nL 101.494091 162.989725 \nL 102.255 162.808525 \nL 104.537727 160.271725 \nL 105.298636 159.788525 \nL 106.059545 158.580525 \nL 107.581364 157.010125 \nL 108.342273 156.345725 \nL 109.103182 154.896125 \nL 109.864091 154.654525 \nL 111.385909 152.842525 \nL 112.146818 152.902925 \nL 112.907727 152.721725 \nL 113.668636 152.842525 \nL 114.429545 152.117725 \nL 115.190455 150.909725 \nL 115.951364 150.064125 \nL 116.712273 148.856125 \nL 117.473182 147.950125 \nL 118.995 146.560925 \nL 119.755909 145.594525 \nL 120.516818 145.534125 \nL 121.277727 144.809325 \nL 122.038636 144.628125 \nL 122.799545 143.963725 \nL 123.560455 143.118125 \nL 124.321364 142.816125 \nL 125.082273 142.695325 \nL 125.843182 142.453725 \nL 126.604091 142.030925 \nL 127.365 141.245725 \nL 128.125909 140.641725 \nL 129.647727 138.527725 \nL 130.408636 137.802925 \nL 131.930455 137.561325 \nL 133.452273 136.776125 \nL 134.213182 136.051325 \nL 134.974091 136.172125 \nL 135.735 135.205725 \nL 136.495909 134.843325 \nL 137.256818 133.816525 \nL 138.017727 133.756125 \nL 138.778636 132.789725 \nL 139.539545 132.850125 \nL 141.061364 131.460925 \nL 141.822273 131.400525 \nL 142.583182 131.883725 \nL 144.105 130.132125 \nL 144.865909 129.105325 \nL 145.626818 128.682525 \nL 146.387727 127.655725 \nL 147.148636 127.353725 \nL 148.670455 126.266525 \nL 149.431364 125.058525 \nL 150.192273 125.118925 \nL 150.953182 124.756525 \nL 151.714091 124.152525 \nL 152.475 124.273325 \nL 153.235909 122.944525 \nL 153.996818 122.219725 \nL 154.757727 122.702925 \nL 155.518636 122.582125 \nL 156.279545 122.280125 \nL 157.040455 121.736525 \nL 157.801364 121.434525 \nL 158.562273 121.253325 \nL 159.323182 121.615725 \nL 160.084091 121.253325 \nL 160.845 120.468125 \nL 161.605909 120.226525 \nL 162.366818 119.562125 \nL 163.127727 119.622525 \nL 163.888636 119.562125 \nL 164.649545 118.716525 \nL 165.410455 118.414525 \nL 166.171364 118.293725 \nL 166.932273 117.629325 \nL 167.693182 117.629325 \nL 168.454091 117.146125 \nL 169.215 117.206525 \nL 169.975909 117.025325 \nL 170.736818 116.058925 \nL 171.497727 116.179725 \nL 172.258636 115.938125 \nL 173.019545 115.575725 \nL 173.780455 115.817325 \nL 174.541364 115.636125 \nL 175.302273 115.756925 \nL 176.063182 115.213325 \nL 176.824091 115.092525 \nL 177.585 115.213325 \nL 178.345909 113.642925 \nL 179.867727 113.340925 \nL 180.628636 112.797325 \nL 181.389545 112.736925 \nL 182.150455 112.374525 \nL 182.911364 112.434925 \nL 184.433182 110.864525 \nL 185.194091 111.408125 \nL 185.955 110.622925 \nL 186.715909 110.441725 \nL 187.476818 110.562525 \nL 188.237727 109.354525 \nL 188.998636 108.810925 \nL 189.759545 107.300925 \nL 190.520455 107.240525 \nL 191.281364 107.542525 \nL 192.042273 106.757325 \nL 192.803182 106.636525 \nL 193.564091 106.757325 \nL 195.085909 106.757325 \nL 195.846818 106.515725 \nL 196.607727 105.609725 \nL 197.368636 105.549325 \nL 198.129545 104.462125 \nL 199.651364 103.133325 \nL 200.412273 102.106525 \nL 201.173182 101.381725 \nL 201.934091 101.623325 \nL 202.695 100.777725 \nL 203.455909 100.294525 \nL 204.216818 100.898525 \nL 204.977727 100.958925 \nL 205.738636 100.777725 \nL 206.499545 100.717325 \nL 207.260455 100.415325 \nL 208.021364 99.509325 \nL 208.782273 98.905325 \nL 210.304091 98.844925 \nL 211.065 97.999325 \nL 211.825909 97.576525 \nL 212.586818 96.549725 \nL 213.347727 97.274525 \nL 214.108636 95.945725 \nL 214.869545 96.066525 \nL 215.630455 95.039725 \nL 216.391364 94.435725 \nL 217.152273 94.133725 \nL 218.674091 92.563325 \nL 219.435 92.623725 \nL 220.195909 93.106925 \nL 220.956818 93.288125 \nL 221.717727 93.710925 \nL 223.239545 92.744525 \nL 224.000455 93.469325 \nL 224.761364 92.744525 \nL 225.522273 92.684125 \nL 226.283182 92.019725 \nL 227.044091 91.898925 \nL 227.805 92.261325 \nL 228.565909 91.415725 \nL 229.326818 92.019725 \nL 230.087727 91.717725 \nL 230.848636 91.053325 \nL 231.609545 90.690925 \nL 232.370455 90.872125 \nL 233.131364 90.932525 \nL 233.892273 91.355325 \nL 234.653182 90.872125 \nL 235.414091 89.784925 \nL 236.175 89.422525 \nL 236.935909 88.878925 \nL 237.696818 88.093725 \nL 238.457727 87.912525 \nL 239.979545 86.644125 \nL 240.740455 88.214525 \nL 241.501364 87.972925 \nL 242.262273 88.033325 \nL 243.023182 89.120525 \nL 245.305909 87.006525 \nL 246.066818 87.308525 \nL 246.827727 86.402525 \nL 247.588636 86.221325 \nL 249.110455 84.892525 \nL 249.871364 83.865725 \nL 251.393182 82.536925 \nL 252.154091 82.476525 \nL 252.915 82.234925 \nL 253.675909 81.751725 \nL 254.436818 81.751725 \nL 255.197727 81.026925 \nL 256.719545 80.604125 \nL 257.480455 80.604125 \nL 258.241364 80.724925 \nL 259.002273 79.456525 \nL 259.763182 79.335725 \nL 260.524091 79.577325 \nL 261.285 79.154525 \nL 262.045909 79.094125 \nL 264.328636 77.886125 \nL 266.611364 79.033725 \nL 267.372273 78.973325 \nL 268.133182 79.335725 \nL 268.894091 78.731725 \nL 269.655 77.825725 \nL 270.415909 77.342525 \nL 271.176818 76.496925 \nL 271.937727 77.342525 \nL 272.698636 77.584125 \nL 273.459545 77.282125 \nL 274.981364 78.127725 \nL 275.742273 77.765325 \nL 277.264091 78.188125 \nL 278.025 76.798925 \nL 278.785909 76.134525 \nL 279.546818 76.315725 \nL 280.307727 74.866125 \nL 281.068636 74.624525 \nL 282.590455 73.778925 \nL 283.351364 73.778925 \nL 284.112273 74.684925 \nL 285.634091 74.262125 \nL 286.395 74.322525 \nL 287.155909 73.899725 \nL 287.916818 74.322525 \nL 288.677727 74.382925 \nL 289.438636 73.597725 \nL 290.199545 74.262125 \nL 290.960455 74.443325 \nL 291.721364 73.537325 \nL 292.482273 73.416525 \nL 293.243182 72.812525 \nL 294.004091 73.295725 \nL 295.525909 73.537325 \nL 296.286818 73.356125 \nL 297.047727 72.812525 \nL 297.808636 72.027325 \nL 298.569545 72.450125 \nL 299.330455 71.544125 \nL 300.091364 70.154925 \nL 300.852273 71.060925 \nL 301.613182 70.879725 \nL 302.374091 69.732125 \nL 303.135 69.671725 \nL 303.895909 68.644925 \nL 304.656818 68.765725 \nL 305.417727 68.342925 \nL 306.939545 69.188525 \nL 307.700455 69.007325 \nL 308.461364 67.980525 \nL 309.983182 66.470525 \nL 311.505 65.322925 \nL 312.265909 65.443725 \nL 313.026818 65.443725 \nL 313.787727 66.289325 \nL 314.548636 66.651725 \nL 315.309545 66.228925 \nL 316.070455 66.591325 \nL 316.831364 64.900125 \nL 317.592273 64.658525 \nL 318.353182 63.812925 \nL 319.114091 63.148525 \nL 319.875 63.208925 \nL 320.635909 63.873325 \nL 321.396818 63.933725 \nL 322.157727 62.846525 \nL 322.918636 63.571325 \nL 323.679545 63.933725 \nL 324.440455 64.114925 \nL 325.201364 63.571325 \nL 325.962273 63.390125 \nL 326.723182 63.631725 \nL 329.005909 62.665325 \nL 329.766818 61.819725 \nL 330.527727 62.061325 \nL 331.288636 62.121725 \nL 332.049545 61.759325 \nL 332.810455 62.000925 \nL 333.571364 61.396925 \nL 334.332273 61.155325 \nL 335.854091 61.396925 \nL 336.615 61.276125 \nL 337.375909 61.638525 \nL 338.136818 61.034525 \nL 338.897727 61.819725 \nL 340.419545 62.604925 \nL 341.180455 61.517725 \nL 341.941364 61.336525 \nL 342.702273 60.490925 \nL 343.463182 60.128525 \nL 344.224091 60.068125 \nL 344.985 60.370125 \nL 345.745909 60.490925 \nL 346.506818 61.336525 \nL 346.506818 61.336525 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_26\">\n    <path clip-path=\"url(#p8207875bcf)\" d=\"M 251.393182 239.758125 \nL 251.393182 22.318125 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:0.75;\"/>\n   </g>\n   <g id=\"line2d_27\">\n    <path clip-path=\"url(#p8207875bcf)\" d=\"M 42.143182 218.799325 \nL 46.708636 216.564525 \nL 47.469545 215.960525 \nL 48.230455 215.658525 \nL 48.991364 215.537725 \nL 49.752273 214.994125 \nL 50.513182 214.148525 \nL 51.274091 213.665325 \nL 52.795909 212.276125 \nL 54.317727 211.128525 \nL 55.078636 211.007725 \nL 55.839545 210.464125 \nL 57.361364 208.712525 \nL 59.644091 207.685725 \nL 61.165909 206.356925 \nL 61.926818 205.450925 \nL 62.687727 205.088525 \nL 63.448636 204.484525 \nL 65.731364 203.276525 \nL 66.492273 202.612125 \nL 68.014091 202.189325 \nL 68.775 201.766525 \nL 69.535909 201.102125 \nL 70.296818 200.075325 \nL 71.057727 199.833725 \nL 71.818636 198.625725 \nL 73.340455 197.357325 \nL 74.101364 196.994925 \nL 74.862273 196.874125 \nL 75.623182 195.968125 \nL 76.384091 195.424525 \nL 77.145 194.639325 \nL 77.905909 193.612525 \nL 78.666818 192.344125 \nL 79.427727 192.042125 \nL 80.188636 191.619325 \nL 80.949545 191.377725 \nL 83.993182 187.995325 \nL 84.754091 186.787325 \nL 85.515 186.424925 \nL 86.275909 184.975325 \nL 87.036818 183.827725 \nL 87.797727 182.982125 \nL 88.558636 182.559325 \nL 89.319545 181.774125 \nL 90.080455 180.807725 \nL 90.841364 179.660125 \nL 93.124091 176.821325 \nL 93.885 175.734125 \nL 94.645909 175.371725 \nL 95.406818 174.344925 \nL 96.167727 173.922125 \nL 96.928636 173.076525 \nL 97.689545 172.774525 \nL 98.450455 172.110125 \nL 99.972273 171.204125 \nL 100.733182 171.747725 \nL 102.255 169.694125 \nL 103.015909 169.633725 \nL 103.776818 168.908925 \nL 104.537727 168.486125 \nL 105.298636 167.459325 \nL 106.059545 166.674125 \nL 106.820455 166.432525 \nL 107.581364 166.009725 \nL 108.342273 165.405725 \nL 109.864091 163.170925 \nL 110.625 162.325325 \nL 111.385909 161.117325 \nL 112.146818 160.815325 \nL 112.907727 160.875725 \nL 113.668636 160.271725 \nL 115.190455 159.486525 \nL 115.951364 158.036925 \nL 116.712273 157.614125 \nL 117.473182 157.010125 \nL 118.234091 155.862525 \nL 118.995 155.077325 \nL 119.755909 153.748525 \nL 120.516818 153.506925 \nL 121.277727 152.842525 \nL 122.038636 151.876125 \nL 122.799545 151.151325 \nL 123.560455 150.668125 \nL 124.321364 149.641325 \nL 125.082273 149.580925 \nL 125.843182 149.278925 \nL 128.125909 147.950125 \nL 128.886818 147.889725 \nL 129.647727 147.648125 \nL 130.408636 147.104525 \nL 131.930455 145.413325 \nL 132.691364 145.413325 \nL 134.974091 143.118125 \nL 135.735 142.574525 \nL 136.495909 142.212125 \nL 137.256818 141.185325 \nL 139.539545 139.977325 \nL 140.300455 139.312925 \nL 141.061364 138.890125 \nL 141.822273 137.259325 \nL 142.583182 135.930525 \nL 144.105 134.722525 \nL 144.865909 133.695725 \nL 145.626818 133.152125 \nL 147.148636 131.521325 \nL 147.909545 131.340125 \nL 148.670455 131.038125 \nL 149.431364 129.528125 \nL 150.192273 128.380525 \nL 150.953182 127.474525 \nL 151.714091 127.172525 \nL 152.475 126.749725 \nL 153.235909 125.964525 \nL 153.996818 125.420925 \nL 154.757727 125.722925 \nL 155.518636 124.756525 \nL 156.279545 124.514925 \nL 157.040455 123.427725 \nL 157.801364 123.306925 \nL 158.562273 122.702925 \nL 159.323182 122.582125 \nL 160.845 121.072125 \nL 161.605909 120.166125 \nL 162.366818 120.166125 \nL 163.127727 120.286925 \nL 163.888636 119.864125 \nL 164.649545 119.078925 \nL 166.171364 118.776925 \nL 166.932273 118.776925 \nL 168.454091 118.595725 \nL 169.215 118.233325 \nL 169.975909 118.595725 \nL 170.736818 117.750125 \nL 171.497727 118.474925 \nL 172.258636 118.233325 \nL 173.019545 118.233325 \nL 173.780455 117.025325 \nL 174.541364 116.723325 \nL 175.302273 116.542125 \nL 176.063182 115.515325 \nL 176.824091 114.246925 \nL 177.585 113.944925 \nL 178.345909 113.884525 \nL 179.106818 112.978525 \nL 182.150455 110.441725 \nL 183.672273 108.629725 \nL 184.433182 108.327725 \nL 185.194091 109.233725 \nL 185.955 109.354525 \nL 187.476818 108.992125 \nL 188.237727 107.784125 \nL 188.998636 107.240525 \nL 191.281364 104.643325 \nL 192.042273 104.824525 \nL 193.564091 103.858125 \nL 194.325 103.737325 \nL 195.085909 103.314525 \nL 195.846818 103.556125 \nL 196.607727 102.468925 \nL 198.129545 101.562925 \nL 198.890455 101.442125 \nL 199.651364 100.354925 \nL 200.412273 100.294525 \nL 201.173182 99.026125 \nL 201.934091 98.784525 \nL 202.695 99.569725 \nL 203.455909 99.871725 \nL 204.216818 99.811325 \nL 205.738636 98.240925 \nL 206.499545 98.120125 \nL 208.021364 98.240925 \nL 208.782273 97.334925 \nL 209.543182 97.697325 \nL 210.304091 97.576525 \nL 211.825909 96.791325 \nL 212.586818 96.730925 \nL 213.347727 97.093325 \nL 214.108636 96.912125 \nL 214.869545 96.247725 \nL 215.630455 95.885325 \nL 217.152273 94.556525 \nL 218.674091 94.858525 \nL 219.435 94.496125 \nL 220.195909 93.469325 \nL 220.956818 92.925725 \nL 221.717727 92.744525 \nL 222.478636 92.744525 \nL 224.761364 91.717725 \nL 225.522273 92.321725 \nL 226.283182 92.684125 \nL 227.044091 92.382125 \nL 227.805 92.200925 \nL 229.326818 92.321725 \nL 230.087727 92.865325 \nL 230.848636 91.778125 \nL 231.609545 92.080125 \nL 233.131364 91.415725 \nL 233.892273 90.811725 \nL 234.653182 91.113725 \nL 235.414091 91.838525 \nL 236.175 91.838525 \nL 236.935909 92.200925 \nL 237.696818 92.261325 \nL 238.457727 92.080125 \nL 239.218636 92.080125 \nL 239.979545 91.838525 \nL 241.501364 92.019725 \nL 242.262273 91.959325 \nL 243.023182 91.596925 \nL 244.545 92.019725 \nL 245.305909 91.294925 \nL 246.066818 91.174125 \nL 246.827727 91.294925 \nL 247.588636 90.992925 \nL 248.349545 91.174125 \nL 249.110455 90.690925 \nL 250.632273 90.811725 \nL 251.393182 90.026525 \nL 252.154091 89.482925 \nL 253.675909 88.939325 \nL 254.436818 88.758125 \nL 255.197727 88.274925 \nL 255.958636 88.093725 \nL 256.719545 87.791725 \nL 258.241364 88.274925 \nL 259.002273 87.731325 \nL 259.763182 87.368925 \nL 260.524091 86.825325 \nL 262.806818 85.677725 \nL 263.567727 85.556925 \nL 264.328636 85.677725 \nL 265.089545 85.315325 \nL 265.850455 85.194525 \nL 267.372273 85.979725 \nL 268.133182 85.858925 \nL 268.894091 85.315325 \nL 270.415909 85.858925 \nL 271.176818 85.254925 \nL 271.937727 85.738125 \nL 272.698636 85.315325 \nL 273.459545 84.348925 \nL 274.981364 83.684525 \nL 277.264091 85.073725 \nL 278.025 84.288525 \nL 278.785909 83.986525 \nL 279.546818 82.718125 \nL 280.307727 82.476525 \nL 281.068636 82.416125 \nL 282.590455 83.080525 \nL 283.351364 82.234925 \nL 284.112273 81.993325 \nL 284.873182 82.295325 \nL 285.634091 82.234925 \nL 286.395 81.872525 \nL 287.155909 82.114125 \nL 287.916818 81.208125 \nL 288.677727 80.483325 \nL 289.438636 80.302125 \nL 290.199545 80.302125 \nL 290.960455 81.630925 \nL 291.721364 81.147725 \nL 292.482273 81.570525 \nL 293.243182 81.449725 \nL 294.004091 81.026925 \nL 294.765 80.845725 \nL 295.525909 80.483325 \nL 296.286818 80.604125 \nL 297.047727 81.147725 \nL 297.808636 80.845725 \nL 298.569545 81.208125 \nL 300.852273 80.906125 \nL 301.613182 80.906125 \nL 302.374091 81.087325 \nL 303.135 82.114125 \nL 303.895909 82.597325 \nL 304.656818 82.597325 \nL 305.417727 83.563725 \nL 306.178636 83.020125 \nL 306.939545 83.926125 \nL 307.700455 83.322125 \nL 308.461364 82.899325 \nL 309.983182 83.080525 \nL 311.505 81.630925 \nL 313.026818 81.751725 \nL 313.787727 81.328925 \nL 314.548636 81.570525 \nL 315.309545 81.026925 \nL 316.070455 81.993325 \nL 316.831364 81.449725 \nL 317.592273 81.328925 \nL 318.353182 80.906125 \nL 319.114091 80.966525 \nL 319.875 80.664525 \nL 320.635909 80.241725 \nL 321.396818 80.241725 \nL 322.157727 80.604125 \nL 322.918636 80.604125 \nL 323.679545 80.241725 \nL 324.440455 79.577325 \nL 325.201364 79.879325 \nL 325.962273 79.758525 \nL 326.723182 78.973325 \nL 327.484091 80.000125 \nL 329.766818 80.604125 \nL 330.527727 80.906125 \nL 332.049545 80.181325 \nL 333.571364 81.026925 \nL 334.332273 81.691325 \nL 335.854091 82.476525 \nL 336.615 83.442925 \nL 337.375909 83.140925 \nL 338.136818 82.536925 \nL 338.897727 83.382525 \nL 339.658636 83.382525 \nL 340.419545 83.624125 \nL 341.941364 83.744925 \nL 342.702273 83.442925 \nL 343.463182 82.899325 \nL 344.224091 82.657725 \nL 344.985 83.261725 \nL 346.506818 82.476525 \nL 346.506818 82.476525 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_28\">\n    <path clip-path=\"url(#p8207875bcf)\" d=\"M 280.307727 239.758125 \nL 280.307727 22.318125 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:0.75;\"/>\n   </g>\n   <g id=\"line2d_29\">\n    <path clip-path=\"url(#p8207875bcf)\" d=\"M 26.925 82.718125 \nL 361.725 82.718125 \n\" style=\"fill:none;stroke:#000000;stroke-dasharray:3,6;stroke-dashoffset:0;stroke-width:0.75;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 239.758125 \nL 26.925 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 361.725 239.758125 \nL 361.725 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 239.758125 \nL 361.725 239.758125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 22.318125 \nL 361.725 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_26\">\n    <!-- Average score over 100 consecutive episodes -->\n    <g transform=\"translate(56.653125 16.318125)scale(0.12 -0.12)\">\n     <defs>\n      <path d=\"M 34.1875 63.1875 \nL 20.796875 26.90625 \nL 47.609375 26.90625 \nz\nM 28.609375 72.90625 \nL 39.796875 72.90625 \nL 67.578125 0 \nL 57.328125 0 \nL 50.6875 18.703125 \nL 17.828125 18.703125 \nL 11.1875 0 \nL 0.78125 0 \nz\n\" id=\"DejaVuSans-65\"/>\n      <path d=\"M 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 8.796875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nL 35.6875 0 \nL 23.484375 0 \nz\n\" id=\"DejaVuSans-118\"/>\n      <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n      <path d=\"M 45.40625 27.984375 \nQ 45.40625 37.75 41.375 43.109375 \nQ 37.359375 48.484375 30.078125 48.484375 \nQ 22.859375 48.484375 18.828125 43.109375 \nQ 14.796875 37.75 14.796875 27.984375 \nQ 14.796875 18.265625 18.828125 12.890625 \nQ 22.859375 7.515625 30.078125 7.515625 \nQ 37.359375 7.515625 41.375 12.890625 \nQ 45.40625 18.265625 45.40625 27.984375 \nz\nM 54.390625 6.78125 \nQ 54.390625 -7.171875 48.1875 -13.984375 \nQ 42 -20.796875 29.203125 -20.796875 \nQ 24.46875 -20.796875 20.265625 -20.09375 \nQ 16.0625 -19.390625 12.109375 -17.921875 \nL 12.109375 -9.1875 \nQ 16.0625 -11.328125 19.921875 -12.34375 \nQ 23.78125 -13.375 27.78125 -13.375 \nQ 36.625 -13.375 41.015625 -8.765625 \nQ 45.40625 -4.15625 45.40625 5.171875 \nL 45.40625 9.625 \nQ 42.625 4.78125 38.28125 2.390625 \nQ 33.9375 0 27.875 0 \nQ 17.828125 0 11.671875 7.65625 \nQ 5.515625 15.328125 5.515625 27.984375 \nQ 5.515625 40.671875 11.671875 48.328125 \nQ 17.828125 56 27.875 56 \nQ 33.9375 56 38.28125 53.609375 \nQ 42.625 51.21875 45.40625 46.390625 \nL 45.40625 54.6875 \nL 54.390625 54.6875 \nz\n\" id=\"DejaVuSans-103\"/>\n      <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n      <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-65\"/>\n     <use x=\"62.533203\" xlink:href=\"#DejaVuSans-118\"/>\n     <use x=\"121.712891\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"183.236328\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"224.349609\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"285.628906\" xlink:href=\"#DejaVuSans-103\"/>\n     <use x=\"349.105469\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"410.628906\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"442.416016\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"494.515625\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"549.496094\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"610.677734\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"649.541016\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"711.064453\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"742.851562\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"804.033203\" xlink:href=\"#DejaVuSans-118\"/>\n     <use x=\"863.212891\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"924.736328\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"965.849609\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"997.636719\" xlink:href=\"#DejaVuSans-49\"/>\n     <use x=\"1061.259766\" xlink:href=\"#DejaVuSans-48\"/>\n     <use x=\"1124.882812\" xlink:href=\"#DejaVuSans-48\"/>\n     <use x=\"1188.505859\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"1220.292969\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"1275.273438\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"1336.455078\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"1399.833984\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"1451.933594\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"1513.457031\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"1568.4375\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"1631.816406\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"1671.025391\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"1698.808594\" xlink:href=\"#DejaVuSans-118\"/>\n     <use x=\"1757.988281\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"1819.511719\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"1851.298828\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"1912.822266\" xlink:href=\"#DejaVuSans-112\"/>\n     <use x=\"1976.298828\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"2004.082031\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"2056.181641\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"2117.363281\" xlink:href=\"#DejaVuSans-100\"/>\n     <use x=\"2180.839844\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"2242.363281\" xlink:href=\"#DejaVuSans-115\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 33.925 59.674375 \nL 127.592188 59.674375 \nQ 129.592188 59.674375 129.592188 57.674375 \nL 129.592188 29.318125 \nQ 129.592188 27.318125 127.592188 27.318125 \nL 33.925 27.318125 \nQ 31.925 27.318125 31.925 29.318125 \nL 31.925 57.674375 \nQ 31.925 59.674375 33.925 59.674375 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_30\">\n     <path d=\"M 35.925 35.416562 \nL 55.925 35.416562 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_31\"/>\n    <g id=\"text_27\">\n     <!-- DQN -->\n     <g transform=\"translate(63.925 38.916562)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 19.671875 64.796875 \nL 19.671875 8.109375 \nL 31.59375 8.109375 \nQ 46.6875 8.109375 53.6875 14.9375 \nQ 60.6875 21.78125 60.6875 36.53125 \nQ 60.6875 51.171875 53.6875 57.984375 \nQ 46.6875 64.796875 31.59375 64.796875 \nz\nM 9.8125 72.90625 \nL 30.078125 72.90625 \nQ 51.265625 72.90625 61.171875 64.09375 \nQ 71.09375 55.28125 71.09375 36.53125 \nQ 71.09375 17.671875 61.125 8.828125 \nQ 51.171875 0 30.078125 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-68\"/>\n       <path d=\"M 39.40625 66.21875 \nQ 28.65625 66.21875 22.328125 58.203125 \nQ 16.015625 50.203125 16.015625 36.375 \nQ 16.015625 22.609375 22.328125 14.59375 \nQ 28.65625 6.59375 39.40625 6.59375 \nQ 50.140625 6.59375 56.421875 14.59375 \nQ 62.703125 22.609375 62.703125 36.375 \nQ 62.703125 50.203125 56.421875 58.203125 \nQ 50.140625 66.21875 39.40625 66.21875 \nz\nM 53.21875 1.3125 \nL 66.21875 -12.890625 \nL 54.296875 -12.890625 \nL 43.5 -1.21875 \nQ 41.890625 -1.3125 41.03125 -1.359375 \nQ 40.1875 -1.421875 39.40625 -1.421875 \nQ 24.03125 -1.421875 14.8125 8.859375 \nQ 5.609375 19.140625 5.609375 36.375 \nQ 5.609375 53.65625 14.8125 63.9375 \nQ 24.03125 74.21875 39.40625 74.21875 \nQ 54.734375 74.21875 63.90625 63.9375 \nQ 73.09375 53.65625 73.09375 36.375 \nQ 73.09375 23.6875 67.984375 14.640625 \nQ 62.890625 5.609375 53.21875 1.3125 \nz\n\" id=\"DejaVuSans-81\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-68\"/>\n      <use x=\"77.001953\" xlink:href=\"#DejaVuSans-81\"/>\n      <use x=\"155.712891\" xlink:href=\"#DejaVuSans-78\"/>\n     </g>\n    </g>\n    <g id=\"line2d_32\">\n     <path d=\"M 35.925 50.094687 \nL 55.925 50.094687 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_33\"/>\n    <g id=\"text_28\">\n     <!-- Double DQN -->\n     <g transform=\"translate(63.925 53.594687)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-68\"/>\n      <use x=\"77.001953\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"138.183594\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"201.5625\" xlink:href=\"#DejaVuSans-98\"/>\n      <use x=\"265.039062\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"292.822266\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"354.345703\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"386.132812\" xlink:href=\"#DejaVuSans-68\"/>\n      <use x=\"463.134766\" xlink:href=\"#DejaVuSans-81\"/>\n      <use x=\"541.845703\" xlink:href=\"#DejaVuSans-78\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p8207875bcf\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"26.925\" y=\"22.318125\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "def plot_results(agents, training_results):\n",
    "    for agent, ts in zip(agents, training_results):\n",
    "        mean, std_dev, _ = ts\n",
    "        episode_solved = np.argmax(mean > 13) + 100\n",
    "        print('{}: Solved after {} episodes'.format(agent[0], episode_solved))\n",
    "\n",
    "        x = np.arange(100, 100 + mean.size)\n",
    "        line = plt.plot(x, mean, label = agent[0])\n",
    "        plt.fill_between(x, mean + std_dev, mean - std_dev, alpha=0.1)\n",
    "        plt.axvline(episode_solved, lw=0.75, color=line[0].get_color())\n",
    "\n",
    "    plt.axhline(13, dashes=(4, 8), lw=0.75, color='black')\n",
    "    plt.xticks(np.arange(1, 1 + mean.size / 100) * 100)\n",
    "    plt.yticks(np.arange(0, 19))\n",
    "    plt.xlabel('Number of episodes')\n",
    "    plt.title('Average score over 100 consecutive episodes')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_results(agents[:2], training_results[:2])\n",
    "plot_results(agents[2:], training_results[2:])"
   ]
  },
  {
   "source": [
    "## 8. Possible improvements\n",
    "\n",
    "By observing the agent play we can see that sometimes this happens.\n",
    "\n",
    "![SegmentLocal](imgs/gif_1.gif \"segment\")\n",
    "\n",
    "One of the reasons for this might be that the states are completely independent from each other. Although the original DQN paper worked directly on pixels, to overcome this issue they provided **four consecutive frames** to the agent, instead of one. This only requires slight modifications to the code, for instance we need to change the input of the network to `4 * state_size` and update the `execute_episode` function to handle four states instead of one, as follows:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_episode_v2(agent, env):,\n",
    "    env_info = env.reset(train_mode=True)[brain_name]\n",
    "    state = env_info.vector_observations[0]\n",
    "    score = 0\n",
    "    done = False\n",
    "    \n",
    "    consecutive_states = [state] * 4  # replicate the first state four times\n",
    "    edited_state = np.array(consecutive_states).flatten()  # merge four states into one vector\n",
    "\n",
    "    while not done:\n",
    "        action = agent.act(edited_state)\n",
    "\n",
    "        env_info = env.step(action)[brain_name]\n",
    "        next_state = env_info.vector_observations[0]\n",
    "        reward = env_info.rewards[0]\n",
    "        done = env_info.local_done[0]\n",
    "\n",
    "        consecutive_states.pop(0)  # remove the oldest state\n",
    "        consecutive_states.append(next_state)  # and add the newest one\n",
    "        edited_next_state = np.array(consecutive_states).flatten()  # then merge again\n",
    "\n",
    "        agent.store(edited_state, action, reward, edited_next_state, done)\n",
    "        score += reward\n",
    "        edited_state = edited_next_state\n",
    "    return score"
   ]
  },
  {
   "source": [
    "Another important improvement could be the use of a **prioritized replay buffer**. This can be implemented by creating a class based on `UniformReplayBuffer` which uses a sum tree instead of a ring buffer, and adding two functions `max_priority` and `update_priority`. We'll also need to modify `add` and `sample` to handle priorities as well.\n",
    "\n",
    "When storing a tuple `(s, a, r, ns, d, p)` the parameter `p` will be the **priority** of the tuple, with $p = |\\delta_t|$. When sampling a batch of `n` tuples, we'll obtain a single tuple `([s], [a], [r], [ns], [d], [w])` where `[w]` is the `n`-rows tensor of **importance sampling weights**, with a single $w = a \\left({1 \\over N} {1 \\over P(i)}\\right)^b {1 \\over \\max_i w_i}$, $a, b \\in [0, 1]$. The $i$-th tuple will be sampled based on $P(i) = \\frac{p_i^a}{\\sum_k o_k^a}$, where $p_i$ is the tuple's priority. Note that there's no need to provide the priority to the agent.\n",
    "\n",
    "The code in the agent would then need to be modified as follows:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store(self, s, a, r, ns, d):\n",
    "    p = self.replay_buffer.max_priority()  # store every new tuple with max priority\n",
    "    self.replay_buffer.add((s, a, r, ns, d, p))\n",
    "    # ...\n",
    "\n",
    "def learn(self):\n",
    "    s, a, r, ns, d, w = self.replay_buffer.sample(self.batch_size)  # now also returns tensor w\n",
    "    self.replay_buffer.update_priority(zip(s, a, r, ns, d, torch.abs(td_delta)))  # update_priority\n",
    "    # ...        \n",
    "    loss = torch.sum(w * (td_delta ** 2))  # weighted mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "agent = QNetworkAgent(DQN, state_size, action_size, UniformReplayBuffer(100_000), dt_dqn)\n",
    "agent.q_local.load_state_dict(torch.load('checkpoint.pth', map_location='cpu'))\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "agent.learning = False\n",
    "state = env_info.vector_observations[0]\n",
    "score = 0\n",
    "done = False\n",
    "while not done:\n",
    "    action = agent.act(state)\n",
    "\n",
    "    env_info = env.step(action)[brain_name]\n",
    "    next_state = env_info.vector_observations[0]\n",
    "    reward = env_info.rewards[0]\n",
    "    done = env_info.local_done[0]\n",
    "\n",
    "    agent.store(state, action, reward, next_state, done)\n",
    "    score += reward\n",
    "    state = next_state\n",
    "print(score)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p1_navigation",
   "language": "python",
   "name": "p1_navigation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}